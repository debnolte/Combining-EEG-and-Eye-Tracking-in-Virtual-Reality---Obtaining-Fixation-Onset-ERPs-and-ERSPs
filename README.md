# Combining EEG and Eye-Tracking in Virtual Reality - Obtaining Fixation-Onset ERPs and ERSPs

The project implemented and tested an eye-movement classification algorithm for data recorded in a 3d, free-viewing, and free-movement virtual environment. It is a velocity-based classification based on the algorithms of the MAD saccade (Keshava et al., 2023; Voloh et al., 2020) and REMoDNav (Dar et al., 2021). The code has been tested in combination with EEG data and can be used to generate fERPs and fERSPs. <br />
The scripts provided here include the classification algorithm itself, analysis scripts, and preprocessing scripts for both eye-tracking and EEG data.
<br />
## References
Dar, Asim H., Wagner, Adina S., & Hanke, Michael. (2021). REMoDNaV: robust eye-movement classification for dynamic stimulation. Behavior Research Methods, 53(1), 399–414.  <br />
<br />
Keshava, A., Gottschewsky, N., Balle, S., Nezami, F. N., Schüler, T., & König, P. (2023). Action affordance affects proximal and distal goal-oriented planning. European Journal of Neuroscience, 57(9), 1546–1560. https://doi.org/10.1111/ejn.15963 <br />
<br />
Voloh, B., Watson, M. R., Konig, S., & Womelsdorf, T. (2020). MAD saccade: Statistically robust saccade threshold estimation via the median absolute deviation. Journal of Eye Movement Research, 12(8). https://doi.org/10.16910/jemr.12.8.3 
