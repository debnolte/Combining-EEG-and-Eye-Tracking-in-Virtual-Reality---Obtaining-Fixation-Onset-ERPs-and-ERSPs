{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56a94d03-a469-4bbe-94cc-95e75dc84944",
   "metadata": {},
   "source": [
    "# Plots created for the publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1841ef66-4392-49ed-89d2-34e02d73de1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset # only run when space is needed (variables will be deleted from memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d799980-8079-4b78-9f3d-51756431ed5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings  # hide warnings\n",
    "import pandas as pd  # operate with dataframes\n",
    "import matplotlib.pyplot as plt  # mother of plots focr Python\n",
    "import numpy as np  # array/matrix operations (e.g. linear algebra)\n",
    "import seaborn as sns  # matplotlib plotting nice with shortcuts\n",
    "from scipy.stats import ks_2samp\n",
    "from scipy.stats import ttest_rel\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "from matplotlib.lines import Line2D\n",
    "import scipy.io  # to load Matlab data\n",
    "import pingouin as pg\n",
    "import math\n",
    "from  matplotlib.patches import Arc\n",
    "import matplotlib.patheffects as pe\n",
    "\n",
    "\n",
    "from scipy.interpolate import interp1d\n",
    "from shapely.geometry import Polygon\n",
    "from matplotlib.patches import ConnectionPatch\n",
    "from tqdm.notebook import tqdm, trange  # mother of progressbars\n",
    "from itertools import groupby\n",
    "import pyxdf  # read XDF files (LSL streams recordings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd9352e-3c20-4c2a-a996-3569ee6674bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "\n",
    "# raw and processed data paths\n",
    "PATH_RAW = \"./data/raw\"\n",
    "PATH_PROC = \"./data/processed\"\n",
    "PATH_FOREYE = \"./data/processed/MAD_sacc\" \n",
    "PATH_EEG = \"./data/processed/EEG\"\n",
    "PATH_HANDLABELS = \"./data/processed/Data_HandLabeling\"\n",
    "PATH_TRG = \"./data/processed/Trigger_MAD\"\n",
    "\n",
    "\n",
    "def pbar_fork_hack():\n",
    "    \"\"\"\n",
    "    Hack to enforce progress bars to be displayed by fork processes on\n",
    "    IPython Apps like Jupyter Notebooks.\n",
    "\n",
    "    Avoids [IPKernelApp] WARNING | WARNING: attempted to send message from fork\n",
    "\n",
    "    Important: pass this function as argument for the initializer parameter\n",
    "    while initializing a multiprocessing pool to make it work. E.g.:\n",
    "\n",
    "    pool = Pool(processes=N_CORES, initializer=pbar_fork_hack)\n",
    "\n",
    "    Source:\n",
    "     - https://github.com/ipython/ipython/issues/11049#issue-306086846\n",
    "     - https://github.com/tqdm/tqdm/issues/485#issuecomment-473338308\n",
    "    \"\"\"\n",
    "    print(\" \", end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939df070-a34c-4dc7-bf02-00769ff4e61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "recordings = pd.read_csv(\"./recordings_village.csv\", index_col=0)\n",
    "\n",
    "# only keep the subjects we will include in the paper!\n",
    "subj_to_inlcude = [1,2,5,7,12,17,18,19,20,21,22,27,29,30,32,33,34,37,38,] # final subjects for the paper  \n",
    "recordings[\"files\"] = [\n",
    "    int(f[:2]) if int(f[:2]) in subj_to_inlcude else 0\n",
    "    for f in recordings[\"file\"]\n",
    "]\n",
    "\n",
    "recordings = recordings[recordings[\"files\"] > 0]\n",
    "recordings = recordings.drop(\"files\", axis=1)\n",
    "\n",
    "display(recordings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873631ae-f310-4045-814f-c70d76642ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# color pallet used in the paper\n",
    "\n",
    "# blue\n",
    "gaze_color_1 = \"#066da8\"#\"#0570b0\"\n",
    "gaze_color_2 = \"#77aacf\"#\"#74a9cf\" #d \n",
    "gaze_color_3 = \"#bfcae0\"#\"#bdc9e1\" #d\n",
    "\n",
    "# red\n",
    "sacc_color_1 = \"#e31a1c\" #d\n",
    "sacc_color_2 = \"#fd8d3c\" #d\n",
    "sacc_color_3 = \"#fecc5c\" #d\n",
    "\n",
    "# green\n",
    "vel_eye_color = \"#238443\" #d\n",
    "vel_head_color = \"#d8b365\" #\"#c2e699\"\n",
    "\n",
    "# grey/other 525252\n",
    "ten_thres_color = \"#525252\"\n",
    "dd_thres_color = \"#a4a1a4\" #\"#bdbdbd\"\n",
    "colliders_color = \"#987284\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362a9769-375b-4a86-ad3e-6b8c25ce4ff9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Experiment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b517ab04-9de4-44c1-86f6-90f9b3c276e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"Arial\" # font name\n",
    "numbersize = 60 #A, B etc.\n",
    "\n",
    "plt.figure(figsize=(30, 20), constrained_layout=True)\n",
    "\n",
    "sns.set_style(\"white\") \n",
    "# grid to have the subplots arranged nicely\n",
    "ax1 = plt.subplot2grid(shape=(2, 4), loc=(0, 0), rowspan=2, colspan=2)\n",
    "ax2 = plt.subplot2grid(shape=(2, 4), loc=(0, 2), rowspan=1, colspan=2)\n",
    "ax3 = plt.subplot2grid(shape=(2, 4), loc=(1, 2), rowspan=1, colspan=2)\n",
    "\n",
    "# load image\n",
    "img = plt.imread(\"./images/IMG_4552.jpg\") # image credits: (c) Simone Reukauf\n",
    "ax1.imshow(img)\n",
    "ax1.axis('off') # no black box surrounding the image\n",
    "ax1.text(0.18, -0.015, 'Photo: (c) Simone Reukauf',fontsize=30, horizontalalignment='center', verticalalignment='center', transform=ax1.transAxes, fontname=fname) # credit\n",
    "\n",
    "ax1.set_title(\"A\", fontsize=numbersize, fontweight=\"bold\",loc=\"left\", x=-0.07, y=1.02, pad=-30, fontname=fname) \n",
    "\n",
    "img = plt.imread(\"./images/unity2.png\")\n",
    "ax2.imshow(img)\n",
    "ax2.axis('off')\n",
    "ax2.set_title(\"B\", fontsize=numbersize, fontweight=\"bold\",loc=\"left\", x=-0.07, y=1.05, pad=-30, fontname=fname) \n",
    "\n",
    "img = plt.imread(\"./images/birds-eye-view.png\")\n",
    "ax3.imshow(img) \n",
    "ax3.axis('off')\n",
    "ax3.set_title(\"C\", fontsize=numbersize, fontweight=\"bold\",loc=\"left\", x=-0.07, y=1.05, pad=-30, fontname=fname) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf102c00-752f-45e6-b343-439af233da42",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Check % of data interpolated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5148c959-bf3b-452e-a502-71664d19eae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Check % of data that has been interpolated.\n",
    "Code taken from 7v - the interpolation\n",
    "Adjusted to save the amount of interpolated data.\n",
    "'''\n",
    "\n",
    "interpolation = {} # save the interpolated data\n",
    "\n",
    "ids = recordings.index.tolist()\n",
    "idd = ids[:]\n",
    "# loop through all subjects\n",
    "for uid in idd:\n",
    "    print(uid)\n",
    "    interpolation[uid] = {}\n",
    "    \n",
    "    # replacement for nans\n",
    "    nanrep = np.nan\n",
    "\n",
    "    # to determin the area around the blinks\n",
    "    min_blink_duration = 0.02\n",
    "    dilate_nan = 0.023  # add it as two samples before and after blink onset\n",
    "\n",
    "    # get the cooridnates\n",
    "    hit_sort = pd.read_csv(f\"{PATH_PROC}/Behavior_new_{uid}.csv\", index_col=0)\n",
    "    hit_pos = pd.read_csv(f\"{PATH_PROC}/HitsSorted_new_{uid}.csv\", index_col=0)\n",
    "\n",
    "    # delete identical rows:\n",
    "    hit_sort = hit_sort[~hit_sort.index.duplicated(keep=\"first\")]\n",
    "    hit_pos = hit_pos[~hit_pos.index.duplicated(keep=\"first\")]\n",
    "\n",
    "    # to check for wrong samples:\n",
    "    x_origin = hit_sort[\"ETWoriginX\"].tolist()\n",
    "\n",
    "    # the data we interpolate\n",
    "    x_coord = hit_sort[\"ETWdirectionX\"].tolist()\n",
    "    hpoo_x = hit_pos[\"HPOOX\"].tolist()\n",
    "\n",
    "    # and get the timestamps\n",
    "    times = hit_sort.index.tolist()\n",
    "    times_hpoo = hit_pos.index.tolist()\n",
    "\n",
    "    # get valid data\n",
    "    val = hit_sort[\"valid\"].tolist()  # original valid stream\n",
    "    \n",
    "    # adjust valid: if both eyes are closed: change to 0.0 in valid\n",
    "    no_valids_corr_df = hit_sort[\n",
    "        (hit_sort.leftBlink == 1.000)\n",
    "        & (hit_sort.rightBlink == 1.000)\n",
    "        & (hit_sort.valid == 1.000)\n",
    "    ]\n",
    "    no_val = [\n",
    "        0.0 if t in no_valids_corr_df.index else 1.0 for t in times\n",
    "    ]  # get a list out of df\n",
    "\n",
    "    # adjust valid: if the position is too far away: change to -2.0 in valid\n",
    "    no_valids_corr_df = hit_sort[\n",
    "        (hit_sort.ETWoriginX < 400.0) & (hit_sort.valid == 1.000)\n",
    "    ]\n",
    "    no_val1 = [\n",
    "        0.0 if t in no_valids_corr_df.index else 1.0 for t in times\n",
    "    ]  # get a list out of df\n",
    "    valid = [\n",
    "        0.0\n",
    "        if (no_val[v] == 0.0) or (no_val1[v] == 0.0) or (val[v] == 0.0)\n",
    "        else 1.0\n",
    "        for v in range(len(val))\n",
    "    ]  # add it t\n",
    "    \n",
    "    # save % of data that is invalid before we do the blink correction\n",
    "    interpolation[uid]['inval_before_blinks'] = (len(valid) - sum(valid))/len(valid)*100\n",
    "\n",
    "    \n",
    "    # to check how many close samples there were\n",
    "    cnt = False\n",
    "    cnt_item = 0.0\n",
    "\n",
    "    # to get the blink onset\n",
    "    blinking = False  # will be true during the blinking\n",
    "    blink_time = 0.0  # will be updated to blink onset\n",
    "    blinks = [0.0] * len(times)\n",
    "    \n",
    "    # go through the entire list of timestamps\n",
    "    for t, item in enumerate(times):\n",
    "        # if this is not part of the hpoo:\n",
    "        if not item in times_hpoo:\n",
    "            hpoo_x.insert(t, nanrep)\n",
    "            times_hpoo.insert(t, item)\n",
    "            \n",
    "        # to check for blinks: get blink onset\n",
    "        if (valid[t] != 1.0) and not blinking:\n",
    "            blinking = True\n",
    "            # get the time of blinking onset\n",
    "            blink_time = item\n",
    "        # if they are over, do:\n",
    "        elif valid[t] == 1.0 and blinking:\n",
    "            # reset the blinking parameter\n",
    "            blinking = False\n",
    "            # get the end of the blink (so the previous time stamp)\n",
    "            it = times[t - 1]\n",
    "            # if the blink duration is bigger than the min blink duration:\n",
    "            # adapt the blink duration plus the dialate_nan\n",
    "            if it - blink_time >= min_blink_duration:\n",
    "                # we want to exchange all the items with nan, so get the time interval we need to change it in:\n",
    "                ts = times[\n",
    "                    times.index(\n",
    "                        list(\n",
    "                            filter(\n",
    "                                lambda i: i >= (blink_time - dilate_nan), times\n",
    "                            )\n",
    "                        )[0]\n",
    "                    ) : times.index(\n",
    "                        list(filter(lambda i: i <= (it + dilate_nan), times))[\n",
    "                            -1\n",
    "                        ]\n",
    "                    )\n",
    "                    + 1\n",
    "                ]  # get all timestamps in the important time window\n",
    "                for t_s in ts:\n",
    "                    # if this is not part of the hpoo (as we add two elements after the current one):\n",
    "                    if not t_s in times_hpoo:\n",
    "                        hpoo_x.insert(times.index(t_s), nanrep)\n",
    "                        times_hpoo.insert(times.index(t_s), item)\n",
    "\n",
    "                    # ETW\n",
    "                    x_coord[times.index(t_s)] = nanrep\n",
    "                    hpoo_x[times.index(t_s)] = nanrep\n",
    "                \n",
    "                    # add the number to blinks\n",
    "                    blinks[times.index(t_s)] = nanrep\n",
    "            # if the blink duration is too small, we do not add an additional window around it\n",
    "            else:\n",
    "                ts = times[\n",
    "                    times.index(\n",
    "                        list(filter(lambda i: i >= (blink_time), times))[0]\n",
    "                    ) : times.index(\n",
    "                        list(filter(lambda i: i <= (it), times))[-1]\n",
    "                    )\n",
    "                    + 1\n",
    "                ]  # get all timestamps in the important time window\n",
    "                for t_s in ts:\n",
    "                    # ETW\n",
    "                    x_coord[times.index(t_s)] = nanrep\n",
    "        \n",
    "                    # hpoo\n",
    "                    hpoo_x[times.index(t_s)] = nanrep\n",
    "                    \n",
    "    # go through the other list and delete all elmenets that are not in time\n",
    "    # so all the elements that we cannot add the the .csv like this\n",
    "    to_del = list(set(times_hpoo) - set(times))\n",
    "    for i in to_del:\n",
    "        hpoo_x.pop(times_hpoo.index(i))\n",
    "        times_hpoo.pop(times_hpoo.index(i))\n",
    "\n",
    "    # create a df out of all the important lists:\n",
    "    for_eye = list(\n",
    "        zip(\n",
    "            times,\n",
    "            valid,\n",
    "            x_coord,\n",
    "            hpoo_x,\n",
    "            blinks,\n",
    "        )\n",
    "    )\n",
    "    for_eye = pd.DataFrame(\n",
    "        for_eye,\n",
    "        columns=[\n",
    "            \"time\",\n",
    "            \"valid\",\n",
    "            \"xcoord\",\n",
    "            \"xhpoo\",\n",
    "            \"blinks\",\n",
    "        ],\n",
    "    )\n",
    "    for_eye.set_index(\"time\")\n",
    "\n",
    "    # get % of data that is considered invalid after the blink correctoin\n",
    "    v_nan = for_eye[~for_eye[\"xcoord\"].isnull()] \n",
    "    interpolation[uid]['inval_after_blinks'] = (len(for_eye) - len(v_nan))/len(for_eye)*100\n",
    "    \n",
    "    # interpolate\n",
    "    for column_name in for_eye:\n",
    "        # do not interpolate these columns\n",
    "        if column_name not in [\n",
    "            \"time\",\n",
    "            \"valid\",\n",
    "        ]:\n",
    "            \n",
    "            b = for_eye[column_name].values.tolist()\n",
    "            # get number of nan\n",
    "            v = [\n",
    "                len(list(group))\n",
    "                for key, group in groupby(b, key=pd.isnull)\n",
    "                if key\n",
    "            ]\n",
    "\n",
    "\n",
    "            # get corresponding time for each group in v\n",
    "            idx = [\n",
    "                idx + 1\n",
    "                for idx in range(len(b) - 1)\n",
    "                if not pd.isnull(b[idx]) and pd.isnull(b[idx + 1])\n",
    "            ]\n",
    "            if pd.isnull(b[0]):\n",
    "                idx.insert(\n",
    "                    0, 0\n",
    "                )  # if the first element is nan, it will be added here\n",
    "\n",
    "            # interpolate data\n",
    "            for_eye[column_name] = for_eye[column_name].interpolate(\n",
    "                method=\"linear\", limit_direction=\"both\"\n",
    "            )\n",
    "            # go through v: if the beginning and end difference is bigger than allowed, replace interpolated data with nan\n",
    "            b = for_eye[column_name].values.tolist()\n",
    "            b = np.array(\n",
    "                b\n",
    "            )  # for the filling in an array is needed instead of a list\n",
    "            for t, item in enumerate(idx):\n",
    "                # finish for the last timestamp\n",
    "                if item + v[t] == len(times):\n",
    "                    break\n",
    "                # if the distance is bigger then 250ms we do not want to interpolate --> replace values with nan\n",
    "                if times[item + v[t]] - times[item] > 0.25:\n",
    "                    b[item : item + v[t]] = np.nan * len(b[item : item + v[t]])\n",
    "\n",
    "            # replace the column with interpolated one\n",
    "            for_eye[column_name] = b.tolist()\n",
    "\n",
    "    # get the amount of data that had been interpolated\n",
    "    b_nan = for_eye[~for_eye[\"xcoord\"].isnull()] \n",
    "    interpolation[uid]['not_interpolated'] = (len(for_eye) - len(b_nan))/len(b)*100\n",
    "    interpolation[uid]['interpolated'] = ((len(for_eye) - len(v_nan)) - (len(for_eye) - len(b_nan)))/len(for_eye)*100\n",
    "\n",
    "# save itas a df\n",
    "interpolation = pd.DataFrame(interpolation).transpose()    \n",
    "display(interpolation)\n",
    "\n",
    "# calculate median \n",
    "print()\n",
    "print(f\"Median Amount of Interpolation: {np.nanmedian(interpolation['interpolated'])}\")\n",
    "\n",
    "# Interquartile range:\n",
    "q75, q25 = np.nanpercentile(interpolation['interpolated'].tolist(), [75, 25])\n",
    "iqr_interp = q75 - q25\n",
    "print(f\"IQR gaze DD: {iqr_interp} ({q25}-{q75})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ae336b-9446-449d-993d-cef76e69d65d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Schematic of translational movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b591b8a-f022-4fef-8843-4553049554e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labelsize = 40 #text\n",
    "legendsize = 40 #ledgend\n",
    "ticksize = 30 #ticks\n",
    "numbersize = 60 #A, B etc.\n",
    "fname = \"Arial\" # font name\n",
    "labelsize = 40 #text\n",
    "linewidth = 5\n",
    "\n",
    "# setting up the figure (sns + plt)\n",
    "sns.set(rc={\"figure.figsize\": (30, 30)})\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "f, (ax1,ax2) = plt.subplots(1,2) # two plots next to each other\n",
    "img = plt.imread(\"images/S1.png\") # we have the same background for both of them\n",
    "\n",
    "######## positions ########\n",
    "# note: 0/0 is in the upper left corner of the image\n",
    "sub_1_x = 80 # x-position of left points\n",
    "sub_2_x = 280 # x-position of the right points\n",
    "sub_y = 380 # y-position of the subject position \n",
    "sub_1_y = 190 # y-position of the left hitpoint\n",
    "sub_2_y = 112 # y-positon of the right hitpoint\n",
    "\n",
    "######## pannel 1 ########\n",
    "ax1.imshow(img, alpha = 0.85) # display the background image\n",
    "\n",
    "# points\n",
    "ax1.scatter([sub_1_x,sub_2_x,sub_1_x,sub_2_x], [sub_y,sub_y,sub_1_y,sub_2_y], marker='o', facecolors='black', \n",
    "            zorder=3, linewidth = 2, edgecolors='black', s=300)\n",
    "# arrows \n",
    "V = np.array([[0,0.535], [0,0.76], [0.575,0.76], [0.565,0]]) # direction of the arrows\n",
    "origin = np.array([[sub_1_x, sub_2_x, sub_1_x, sub_1_x],[sub_y, sub_y, sub_y, sub_y]]) # origin points: [all x coords], [all y coords]\n",
    "# create the arrows\n",
    "ax1.quiver(*origin, V[:,0], V[:,1], color=[gaze_color_1,sacc_color_1,vel_eye_color, ten_thres_color], \n",
    "           scale=1, linewidth = 0.75, edgecolor='black', width=0.011)\n",
    "# add all text\n",
    "ax1.text(sub_1_x, sub_y+28, 'Subject\\nPosition 1', horizontalalignment='center', verticalalignment='center', rotation=0, \n",
    "         color='black', size=labelsize, weight=\"bold\", fontname=fname, \n",
    "         bbox=dict(facecolor='w', edgecolor='black', boxstyle='round,pad=0.2'))\n",
    "ax1.text(sub_2_x, sub_y+28, 'Subject\\nPosition 2', horizontalalignment='center', verticalalignment='center', rotation=0, \n",
    "         color='black', size=labelsize, weight=\"bold\", fontname=fname, \n",
    "         bbox=dict(facecolor='w', edgecolor='black', boxstyle='round,pad=0.2'))\n",
    "ax1.text(sub_1_x+(sub_2_x-sub_1_x)/2, sub_y, 'Translation', horizontalalignment='center', verticalalignment='center', rotation=0, \n",
    "         color=ten_thres_color, size=labelsize, weight=\"bold\", fontname=fname,\n",
    "         bbox=dict(facecolor='w', edgecolor='black', boxstyle='round,pad=0.2'))\n",
    "ax1.text(sub_1_x, sub_1_y-28, 'Hit\\nPoint 1', horizontalalignment='center', verticalalignment='center', rotation=0, \n",
    "         color='black', size=labelsize, weight=\"bold\", fontname=fname, \n",
    "         bbox=dict(facecolor='w', edgecolor='black', boxstyle='round,pad=0.2'))\n",
    "ax1.text(sub_2_x, sub_2_y-28, 'Hit\\nPoint 2', horizontalalignment='center', verticalalignment='center', rotation=0,\n",
    "         color='black', size=labelsize, weight=\"bold\", fontname=fname, \n",
    "         bbox=dict(facecolor='w', edgecolor='black', boxstyle='round,pad=0.2'))\n",
    "# remove axis ticks\n",
    "ax1.set_xticks([])\n",
    "ax1.set_yticks([])\n",
    "\n",
    "\n",
    "\n",
    "######## pannel 2 ########\n",
    "ax2.imshow(img, alpha = 0.85) # display the background image\n",
    "\n",
    "# points\n",
    "ax2.scatter([sub_1_x,sub_2_x,sub_1_x,sub_2_x], [sub_y,sub_y,sub_1_y,sub_2_y], marker='o', facecolors='black', \n",
    "            zorder=3, linewidth = 2, edgecolors='black', s=300)\n",
    "\n",
    "# gaze directions (lines instead of arrows)\n",
    "ax2.plot([sub_2_x,sub_2_x], [sub_y,sub_2_y], linestyle='solid', marker='', color='k', alpha = 0.5, \n",
    "         zorder=1, linewidth = linewidth+2.5) # outline \n",
    "ax2.plot([sub_2_x,sub_2_x], [sub_y,sub_2_y], linestyle='solid', marker='', color=dd_thres_color, alpha = 0.5, \n",
    "         zorder=1, linewidth = linewidth)\n",
    "ax2.plot([sub_1_x+0.4,sub_1_x+0.4], [sub_y,sub_1_y], linestyle='solid', marker='', color='k', alpha = 1, \n",
    "         zorder=1, linewidth = linewidth+2.5) # outline \n",
    "line_1 = Line2D([sub_1_x,sub_1_x], [sub_y,sub_1_y], linestyle='solid', marker='', color=ten_thres_color, alpha = 0.8, \n",
    "                zorder=1, linewidth = linewidth)\n",
    "ax2.add_line(line_1)\n",
    "line_2 = Line2D([sub_1_x,sub_2_x], [sub_y,sub_2_y], linestyle='solid', marker='', color=ten_thres_color, alpha = 0.8, \n",
    "                zorder=1, linewidth = linewidth, \n",
    "               path_effects=[pe.Stroke(linewidth=linewidth+2.5, foreground='black'), pe.Normal()])\n",
    "ax2.add_line(line_2)\n",
    "\n",
    "# arrow\n",
    "V = np.array([[0,0.222], [0,0.222], [0.575,0.222]]) # direction of to arrows \n",
    "origin = np.array([[sub_1_x, sub_1_x, sub_1_x],[sub_y, sub_1_y, sub_1_y]]) # origin points: [all x coords], [all y coords]\n",
    "# plot the arrows\n",
    "ax2.quiver(*origin, V[:,0], V[:,1], color=[sacc_color_1,sacc_color_1,vel_eye_color], scale=1, linewidth = 0.75, \n",
    "           edgecolor='black', width=0.011)\n",
    "\n",
    "# v_gaze_inplane - line \n",
    "ax2.plot([sub_1_x,sub_2_x], [sub_2_y,sub_2_y], linestyle='solid', marker='', color=gaze_color_1, alpha = 1, zorder=1, \n",
    "         linewidth = linewidth, path_effects=[pe.Stroke(linewidth=linewidth+2.5, foreground='black'), pe.Normal()])\n",
    "\n",
    "# draw the angle \n",
    "l1xy = line_1.get_xydata()\n",
    "# calcualte the angle between line1 and x-axis\n",
    "slope1 = (l1xy[1][1] - l1xy[0][1]) / float(l1xy[1][0] - l1xy[0][0])\n",
    "angle1 = math.degrees(math.atan(slope1)) # Taking only the positive angle\n",
    "l2xy = line_2.get_xydata()\n",
    "# calculate the angle between line2 and x-axis\n",
    "slope2 = (l2xy[1][1] - l2xy[0][1]) / float(l2xy[1][0] - l2xy[0][0])\n",
    "angle2 = math.degrees(math.atan(slope2))\n",
    "\n",
    "# now use this infromatino to draw an angle between the two lines\n",
    "theta1 = min(angle1, angle2)\n",
    "theta2 = max(angle1, angle2)\n",
    "angle = theta2 - theta1\n",
    "offset = 160\n",
    "origin = [sub_1_x,sub_y]\n",
    "len_x_axis = 1\n",
    "len_y_axis = 1\n",
    "angle_plot = Arc(origin, len_x_axis*offset, len_y_axis*offset, 0, theta1, theta2, color=sacc_color_2, zorder=0.5, \n",
    "                label = str(angle)+u\"\\u00b0\", linewidth = linewidth+8,\n",
    "                path_effects=[pe.Stroke(linewidth=linewidth+10.5, foreground='black'), pe.Normal()])\n",
    "ax2.add_patch(angle_plot) # To display the angle arc\n",
    "\n",
    "# add all text\n",
    "ax2.text(sub_1_x, sub_2_y+(sub_1_y-sub_2_y)/2, 'eye-vec', horizontalalignment='center', verticalalignment='center', \n",
    "         rotation=0, color=sacc_color_1, size=labelsize, weight=\"bold\", fontname=fname, \n",
    "         bbox=dict(facecolor='w', edgecolor='black', boxstyle='round,pad=0.2'))\n",
    "ax2.text(sub_1_x+(sub_2_x-sub_1_x)/2, sub_2_y, 'v-eye-in-plane', horizontalalignment='center', verticalalignment='center', \n",
    "         rotation=0, color=gaze_color_1, size=labelsize, weight=\"bold\", fontname=fname, \n",
    "         bbox=dict(facecolor='w', edgecolor='black', boxstyle='round,pad=0.2'))\n",
    "ax2.text(sub_1_x+(sub_2_x-sub_1_x)/2, sub_2_y+(sub_1_y-sub_2_y)/2, 'v-eye-vec', horizontalalignment='center', verticalalignment='center', \n",
    "         rotation=0, color=vel_eye_color, size=labelsize, weight=\"bold\", fontname=fname, \n",
    "         bbox=dict(facecolor='w', edgecolor='black', boxstyle='round,pad=0.2'))\n",
    "ax2.text(sub_1_x+14, sub_y-40, 'w-eye', horizontalalignment='center', verticalalignment='center', \n",
    "         rotation=0, color=sacc_color_2, size=labelsize+12, weight=\"bold\", fontname=fname, \n",
    "         bbox=dict(facecolor='w', edgecolor='black', boxstyle='round,pad=0.2'))\n",
    "\n",
    "ax2.set_xticks([])\n",
    "ax2.set_yticks([])\n",
    "\n",
    "ax1.set_title(\"A\", fontsize=numbersize, fontweight=\"bold\",loc=\"left\", x=-0.1, y=1.05, pad=-30, fontname=fname)\n",
    "ax2.set_title(\"B\", fontsize=numbersize, fontweight=\"bold\",loc=\"left\", x=-0.1, y=1.05, pad=-30, fontname=fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0c52d3-ec52-4ec4-9e1f-c367a73a1ca4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# For LSL part of paper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7daedcfa-bf82-41de-9545-46a650e7e1e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Check the differnce between the beginning and end.\n",
    "'''\n",
    "\n",
    "ids = recordings.index.tolist()\n",
    "idd = ids[:]\n",
    "\n",
    "stats = {} # df to save the results\n",
    "# loop through all\n",
    "for uid in idd:\n",
    "    stats[uid] = {}\n",
    "    # load raw data\n",
    "    part = recordings.loc[uid].file\n",
    "    data, _ = pyxdf.load_xdf(f\"{PATH_RAW}/{part}\")\n",
    "\n",
    "    starts = [] # save all Unity starts\n",
    "    ends = [] # save all unity ends\n",
    "    # loop through all streams\n",
    "    for s in data:\n",
    "        # stream name\n",
    "        s_name = s[\"info\"][\"name\"][0]\n",
    "        # if EEG signal, save start and end\n",
    "        if \"openvibeSignal\" in s_name:\n",
    "            time_eeg = s[\"time_stamps\"][0]\n",
    "            time_eeg_end = s[\"time_stamps\"][-1]\n",
    "        # if not EEG, save start and end\n",
    "        elif \"openvibeMarkers\" not in s_name:\n",
    "            starts.append(s[\"time_stamps\"][0])\n",
    "            ends.append(s[\"time_stamps\"][-1])\n",
    "        # to compare difference between Unity start and ETW start (currently set to zero)\n",
    "        if \"EyeTrackingWorld\" in s_name:\n",
    "            et_start = s[\"time_stamps\"][0]\n",
    "\n",
    "    # get the difference of the start and end\n",
    "    start = min(starts) - time_eeg\n",
    "    end = max(ends) - time_eeg_end\n",
    "    \n",
    "    stats[uid]['start'] = start\n",
    "    stats[uid]['end'] = end\n",
    "    stats[uid]['difference'] = end - start\n",
    "stats = pd.DataFrame(stats).transpose()\n",
    "display(stats)\n",
    "\n",
    "# calculate median and IQR\n",
    "print()\n",
    "print(f\"Median temporal shift: {round(np.nanmedian(stats['difference']),3)*1000}\")\n",
    "q75, q25 = np.nanpercentile(stats['difference'].tolist(), [75, 25])\n",
    "iqr_seg = q75 - q25\n",
    "print(f\"IQR gaze DD: {iqr_seg} ({round(q25,3)*1000}-{round(q75,3)*1000})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a479c71-6fd4-4ce6-9385-a7c2e921c5a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data for Manual Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ba2174-bd70-4671-9f25-3eb71334ec9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "For the manual classification, we take the recorded data before interpolation and blink detection.\n",
    "'''\n",
    "ids = recordings.index.tolist()\n",
    "idd = ids[:1]\n",
    "# loop through all subjects\n",
    "for uid in idd:\n",
    "    # get the data before we interpolate (so the raw data measured)\n",
    "    hit_sort = pd.read_csv(f\"{PATH_PROC}/Behavior_new_{uid}.csv\", index_col=0)\n",
    "    # get the timestamps\n",
    "    times = hit_sort.index.tolist()\n",
    "    \n",
    "    # adjust the valid data\n",
    "    val = hit_sort[\"valid\"].tolist()  # original valid stream\n",
    "    # adjust valid: if both eyes are closed: change to 0.0 in valid\n",
    "    no_valids_corr_df = hit_sort[\n",
    "        (hit_sort.leftBlink == 1.000)\n",
    "        & (hit_sort.rightBlink == 1.000)\n",
    "        & (hit_sort.valid == 1.000)\n",
    "    ]\n",
    "    no_val = [\n",
    "        0.0 if t in no_valids_corr_df.index else 1.0 for t in times\n",
    "    ]  # get a list out of df\n",
    "    # adjust valid: if the position is too far away: change to -2.0 in valid\n",
    "    no_valids_corr_df = hit_sort[\n",
    "        (hit_sort.ETWoriginX < 400.0) & (hit_sort.valid == 1.000)\n",
    "    ]\n",
    "    no_val1 = [\n",
    "        0.0 if t in no_valids_corr_df.index else 1.0 for t in times\n",
    "    ]  # get a list out of df\n",
    "    valid = [\n",
    "        0.0\n",
    "        if (no_val[v] == 0.0) or (no_val1[v] == 0.0) or (val[v] == 0.0)\n",
    "        else 1.0\n",
    "        for v in range(len(val))\n",
    "    ]  # add it t\n",
    "    \n",
    "    # save valid data so that we have the information in only one list\n",
    "    hit_sort[\"valid\"] = valid\n",
    "    \n",
    "\n",
    "    # change column names so that they are consistent with for_eye\n",
    "    hit_sort[\"xcoord\"] = hit_sort[\"ETWdirectionX\"]\n",
    "    hit_sort[\"ycoord\"] = hit_sort[\"ETWdirectionY\"]\n",
    "    hit_sort[\"zcoord\"] = hit_sort[\"ETWdirectionZ\"]\n",
    "    hit_sort[\"time\"] = times\n",
    "    \n",
    "    # only select a subset of columns \n",
    "    columns = [\n",
    "        \"time\",\n",
    "        \"valid\",\n",
    "        \"xcoord\",\n",
    "        \"ycoord\",\n",
    "        \"zcoord\",\n",
    "    ]\n",
    "    hit_sort = hit_sort[columns]\n",
    "    \n",
    "    # save df:\n",
    "    hit_sort.to_csv(f\"{PATH_HANDLABELS}/hand_labeling_{uid}.csv\", index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761fd998-98ff-44a0-a792-08858c271ae8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Segment Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb77024-f0c4-4b6a-800c-a5c7a77f0f68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save the median interval duration of data-driven \n",
    "list_interval_dur = []\n",
    "\n",
    "ids = recordings.index.tolist()\n",
    "idd = ids[:]\n",
    "# loop though all data\n",
    "for it,uid in enumerate(idd):\n",
    "    # load the interval df\n",
    "    int_data = pd.read_csv(\n",
    "        f\"{PATH_FOREYE}/interval_mad_wobig_{uid}.csv\", index_col=0\n",
    "    )\n",
    "    # go through all intervals and save the duration for each of them\n",
    "    interval_dur = []\n",
    "    for i in int_data.index.tolist():\n",
    "        interval_dur = interval_dur + [int_data.iloc[i][\"end\"] - int_data.iloc[i][\"start\"]]\n",
    "        \n",
    "    # add the value to the list of all subjects\n",
    "    list_interval_dur = list_interval_dur + [np.median(interval_dur)]\n",
    "    \n",
    "    \n",
    "# transfrom the list_interval_dur list into a df for statistics\n",
    "list_interval_dur_df = list(zip(list_interval_dur,))\n",
    "list_interval_dur_df = pd.DataFrame(list_interval_dur_df,columns=[\"average_interval_len\",],)\n",
    "# display min, max, median and mean\n",
    "print()\n",
    "print(f\"Min Data Segment Duration: {round(np.nanmin(list_interval_dur_df['average_interval_len']),3)}\")\n",
    "print(f\"Max Data Segment Duration: {round(np.nanmax(list_interval_dur_df['average_interval_len']),3)}\")\n",
    "print(f\"Median Data Segment Duration: {round(np.nanmedian(list_interval_dur_df['average_interval_len']),3)}\")\n",
    "print(f\"Mean Data Segment Duration: {round(np.nanmean(list_interval_dur_df['average_interval_len']),3)}\")\n",
    "# Interquartile range:\n",
    "q75, q25 = np.nanpercentile(list_interval_dur_df['average_interval_len'].tolist(), [75, 25])\n",
    "iqr_seg = q75 - q25\n",
    "print(f\"IQR gaze DD: {iqr_seg} ({round(q25,3)}-{round(q75,3)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94405d3d-f003-49ec-8c98-6880cf79e08a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Classification Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2618f51b-603e-46f6-b318-5b60ce32ccf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this can be done for all subjects if desired\n",
    "ids = recordings.index.tolist()\n",
    "idd = ids[:1] # right now, we only plot one, but this code can also be used to check the individual subjects\n",
    "\n",
    "# select a short window to plot\n",
    "window_lower = 647.2 # s: time stamp of the start of the window\n",
    "window_upper = 649.5 # s: time stamp of he end of the window\n",
    "\n",
    "# define size of: \n",
    "labelsize = 40 # text\n",
    "legendsize = 40 # ledgend\n",
    "ticksize = 30 # ticks\n",
    "numbersize = 60 # A, B etc.\n",
    "fname = \"Arial\" # font name\n",
    "\n",
    "# for the grid of the plot\n",
    "nr_r = 32 # number of rwos\n",
    "rs = 6 # rowspan\n",
    "\n",
    "# loop through the subejcts you want to plot\n",
    "for i, uid in enumerate(idd):\n",
    "    # prepare the figure layout\n",
    "    f = plt.figure(figsize=(30, 34), constrained_layout=True)\n",
    "    sns.set_style(\"white\") \n",
    "    ax0 = plt.subplot2grid(shape=(nr_r, 1), loc=(0, 0), rowspan=rs) # 10-ssecond hit points\n",
    "    ax1 = plt.subplot2grid(shape=(nr_r, 1), loc=(6, 0), rowspan=rs) # data-driven hit points\n",
    "    ax2 = plt.subplot2grid(shape=(nr_r, 1), loc=(13, 0), rowspan=rs) # 10-second gaze direction\n",
    "    ax3 = plt.subplot2grid(shape=(nr_r, 1), loc=(19, 0), rowspan=rs) # data-driven gaze direction\n",
    "    ax4 = plt.subplot2grid(shape=(nr_r, 1), loc=(26, 0), rowspan=rs) # velocities \n",
    "    \n",
    "\n",
    "    # creat text \n",
    "    ax0.text(647.15,60, '10-Second Method', horizontalalignment='left', verticalalignment='center', rotation=0,\n",
    "            size=labelsize, fontname=fname, bbox=dict(facecolor='w', boxstyle='round,pad=0.2'))\n",
    "    ax1.text(647.15,60, 'Data-Driven Method', horizontalalignment='left', verticalalignment='center', rotation=0,\n",
    "            size=labelsize, fontname=fname, bbox=dict(facecolor='w', boxstyle='round,pad=0.2'))\n",
    "    ax2.text(647.15,0.86, '10-Second Method', horizontalalignment='left', verticalalignment='center', rotation=0,\n",
    "            size=labelsize, fontname=fname, bbox=dict(facecolor='w', boxstyle='round,pad=0.2'))\n",
    "    ax3.text(647.15,0.86, 'Data-Driven Method', horizontalalignment='left', verticalalignment='center', rotation=0,\n",
    "            size=labelsize, fontname=fname, bbox=dict(facecolor='w', boxstyle='round,pad=0.2'))\n",
    "    \n",
    "    # to allow for loops\n",
    "    axis = [ax0, ax1, ax2, ax3, ax4]\n",
    "    \n",
    "    # a loop for the 10-second and data-driven method:\n",
    "    for fe in range(2):\n",
    "        # loop for hit points and gaze direction\n",
    "        for gh in range(2):\n",
    "            # load data\n",
    "            # 10-second\n",
    "            if fe == 0:\n",
    "                for_eye = pd.read_csv(\n",
    "                    f\"{PATH_FOREYE}/correTS__10sec_{uid}.csv\", index_col=\"time\"\n",
    "                )\n",
    "                half_t = \"10-Second\" # second half of title\n",
    "            # data-driven\n",
    "            else:\n",
    "                for_eye = pd.read_csv(\n",
    "                    f\"{PATH_FOREYE}/correTS_mad_wobig_{uid}.csv\",\n",
    "                    index_col=\"time\", \n",
    "                )\n",
    "                half_t = \"Data-Driven\" # second half of title\n",
    "            if gh == 0:\n",
    "                titel = \"Hit Points: \" + half_t \n",
    "            else:\n",
    "                titel = \"Gaze Directions: \" + half_t\n",
    "                \n",
    "            # get the direction vector\n",
    "            if gh == 1:\n",
    "                # as we do not save this, we have to recompute, considering the translational movement\n",
    "                # get individual coordinates\n",
    "                # eye position\n",
    "                Xcorr_position = for_eye[\"xcoord_orig\"].tolist()\n",
    "                Ycorr_position = for_eye[\"ycoord_orig\"].tolist()\n",
    "                Zcorr_position = for_eye[\"zcoord_orig\"].tolist()\n",
    "                subj = list(\n",
    "                    zip(Xcorr_position, Ycorr_position, Zcorr_position)\n",
    "                )\n",
    "\n",
    "                # hit points\n",
    "                hpooX = for_eye[\"xhpoo\"].tolist()\n",
    "                hpooY = for_eye[\"yhpoo\"].tolist()\n",
    "                hpooZ = for_eye[\"zhpoo\"].tolist()\n",
    "                hpoo = list(zip(hpooX, hpooY, hpooZ))\n",
    "\n",
    "                # gaze_vec(t) is a unit vector in the direction of the gaze (eye+head) in world coordinates\n",
    "                g_vec = [\n",
    "                    np.array(hpoo[v] - np.array(subj[v]))\n",
    "                    for v in range(len(subj))\n",
    "                ]\n",
    "                gaze_vec = [\n",
    "                    np.array(v) / np.linalg.norm(np.array(v)) for v in g_vec\n",
    "                ]\n",
    "                \n",
    "                # create df our of the direction vector to plot it\n",
    "                gaze_vec = pd.DataFrame(\n",
    "                    gaze_vec, columns=[\"gvx\", \"gvy\", \"gvz\"]\n",
    "                )\n",
    "                gaze_vec[\"time\"] = for_eye.index.tolist()\n",
    "                gaze_vec = gaze_vec.set_index(\"time\")\n",
    "                # add it to for_eye so we can differentiate between gaze and saccade\n",
    "                for_eye = pd.concat([for_eye, gaze_vec], axis=1)\n",
    "            \n",
    "            # get time:\n",
    "            ts = for_eye.index.tolist()  # to make it easier\n",
    "            # get a shot time interval, defined by window_lower and window_upper\n",
    "            time = ts[\n",
    "                ts.index(\n",
    "                    list(filter(lambda i: i > window_lower, ts))[0]\n",
    "                ) : ts.index(list(filter(lambda i: i < window_upper, ts))[-1])\n",
    "                + 1\n",
    "            ]  # get all timestamps in the important time window\n",
    "\n",
    "            # now use the short time list to shorten the df\n",
    "            for_eye = for_eye.iloc[\n",
    "                ts.index(time[0]) : (ts.index(time[-1]) + 1)\n",
    "            ]\n",
    "            \n",
    "            \n",
    "            # hit points:\n",
    "            if gh == 0:\n",
    "                # substract 600 from the x and y coordinates for easier plotting (this is due to the\n",
    "                # coordinate system of the Unity project)\n",
    "                for_eye[\"xhpoo\"] = list(\n",
    "                    map(lambda x: x - 600, for_eye[\"xhpoo\"].tolist())\n",
    "                )  \n",
    "                for_eye[\"zhpoo\"] = list(\n",
    "                    map(lambda x: x - 600, for_eye[\"zhpoo\"].tolist())\n",
    "                )  \n",
    "            \n",
    "            # get the timepoints whenever a new collider was hit (plottet as faint lines)\n",
    "            hon = for_eye[\"hon\"].tolist()\n",
    "            hon_ts = [\n",
    "                ti for cnt, ti in enumerate(time) if isinstance(hon[cnt], str)\n",
    "            ]  # timestamps\n",
    "\n",
    "            # separate between gazes and saccades to be plotted in different colors\n",
    "            # get gazes:\n",
    "            gaze = for_eye[~for_eye[\"isFix\"].isnull()]\n",
    "            gaze = gaze[~gaze[\"long_events\"].isnull()]\n",
    "            # get saccades:\n",
    "            sacc = for_eye[~for_eye.index.isin(gaze.index)]\n",
    "            sacc = sacc[~sacc[\"long_events\"].isnull()]\n",
    "\n",
    "            # rename the columns, so that the plotting can be donefor gaze direction and hit points with the same code\n",
    "            # and for the ledgend to be the same\n",
    "            if gh == 0:\n",
    "                gaze = gaze.rename(\n",
    "                    {\"xhpoo\": \"Gaze x\", \"yhpoo\": \"Gaze y\", \"zhpoo\": \"Gaze z\"}, axis=1\n",
    "                )\n",
    "                sacc = sacc.rename(\n",
    "                    {\"xhpoo\": \"Sacc x\", \"yhpoo\": \"Sacc y\", \"zhpoo\": \"Sacc z\"}, axis=1\n",
    "                )\n",
    "            else:\n",
    "                gaze = gaze.rename(\n",
    "                    {\"gvx\": \"Gaze x\", \"gvy\": \"Gaze y\", \"gvz\": \"Gaze z\"}, axis=1\n",
    "                )\n",
    "\n",
    "                sacc = sacc.rename(\n",
    "                    {\"gvx\": \"Sacc x\", \"gvy\": \"Sacc y\", \"gvz\": \"Sacc z\"}, axis=1\n",
    "                )\n",
    "\n",
    "            # plot long events as outliers\n",
    "            long_events = for_eye[for_eye[\"long_events\"].isnull()]\n",
    "            long_events = long_events.rename({\"xhpoo\": \"outliers\"}, axis=1)\n",
    "            \n",
    "            # get the blins\n",
    "            blinks = for_eye[for_eye[\"blinks\"].isnull()]\n",
    "\n",
    "            # get the axis to plot:\n",
    "            if gh == 0:\n",
    "                axis_nr = fe # hit points\n",
    "            else:\n",
    "                axis_nr = 2+fe # gaze direction\n",
    "\n",
    "            # plot collider changes:\n",
    "            for x, xc in enumerate(hon_ts):\n",
    "                if not np.isnan(xc):\n",
    "                    axis[axis_nr].axvline(\n",
    "                        x=xc, color=colliders_color, alpha=0.4, label=\"_Hidden label\"\n",
    "                    )\n",
    "\n",
    "            # assign colors to the different columns\n",
    "            color_gaze = {\n",
    "                \"Gaze x\": gaze_color_1,\n",
    "                \"Gaze y\": gaze_color_2,\n",
    "                \"Gaze z\": gaze_color_3,\n",
    "            }\n",
    "            color_sacc = {\n",
    "                \"Sacc x\": sacc_color_1,\n",
    "                \"Sacc y\": sacc_color_2, \n",
    "                \"Sacc z\": sacc_color_3,\n",
    "            }\n",
    "            \n",
    "            # plot the data\n",
    "            gaze[[\"Gaze x\", \"Gaze y\", \"Gaze z\"]].plot(\n",
    "                color=[\n",
    "                    color_gaze.get(x, \"#333333\")\n",
    "                    for x in gaze[[\"Gaze x\", \"Gaze y\", \"Gaze z\"]]\n",
    "                ],\n",
    "                ax=axis[axis_nr],\n",
    "                marker=\"o\", ms=8,\n",
    "                ls=\"\",\n",
    "            )\n",
    "            sacc[[\"Sacc x\", \"Sacc y\", \"Sacc z\"]].plot(\n",
    "                color=[\n",
    "                    color_sacc.get(x, \"#333333\")\n",
    "                    for x in sacc[[\"Sacc x\", \"Sacc y\", \"Sacc z\"]]\n",
    "                ],\n",
    "                ax=axis[axis_nr],\n",
    "                marker=\"o\", ms=8,\n",
    "                ls=\"\",\n",
    "            )\n",
    "\n",
    "            # we only want x-ticks for the last plot\n",
    "            axis[axis_nr].set_xticklabels([])\n",
    "            \n",
    "            # we only want the legend in the first and last plot\n",
    "            if axis_nr > 0 :\n",
    "                axis[axis_nr].get_legend().remove()\n",
    "            else:\n",
    "                handles, labels = axis[0].get_legend_handles_labels()\n",
    "                axis[axis_nr].get_legend().remove()\n",
    "                \n",
    "            axis[axis_nr].xaxis.label.set_visible(False) # no x-axis label either\n",
    "            axis[axis_nr].set_ylabel(\"Coordinates\", fontsize=labelsize, fontname=fname) # y-axis label\n",
    "            # change the ticksize and fontname \n",
    "            for label in axis[axis_nr].get_yticklabels():\n",
    "                label.set_fontproperties(fname)\n",
    "            axis[axis_nr].yaxis.set_tick_params(labelsize=ticksize)  # change tick size\n",
    "            \n",
    "            # we want to plot the last plot only once\n",
    "            if fe == 0 and gh == 0:\n",
    "                # head velcoity\n",
    "                axis[4].plot(\n",
    "                    time, for_eye[\"HT_combined_vel\"].tolist(), vel_head_color,linestyle =\":\",linewidth=5, label=\"Angular Velocity (Head)\"\n",
    "                )\n",
    "                # eye velocity\n",
    "                axis[4].plot(\n",
    "                    time,\n",
    "                    for_eye[\"combined_vel\"].tolist(),\n",
    "                    vel_eye_color,\n",
    "                    linestyle = \"--\",\n",
    "                    linewidth=3,\n",
    "                    label=\"Angular Velocity (Eye)\",\n",
    "                    alpha=0.9\n",
    "                )\n",
    "                # get the colors for the thresholds\n",
    "                c = [ten_thres_color, dd_thres_color]\n",
    "            if gh == 0:\n",
    "                # plot the threshold for the 10-second and data-driven intervals\n",
    "                axis[4].plot(\n",
    "                    time,\n",
    "                    for_eye[\"thresh\"].tolist(),\n",
    "                    c[fe],\n",
    "                    linewidth=4,\n",
    "                    label=half_t + \" Threshold\",\n",
    "                )\n",
    "\n",
    "\n",
    "    f.legend(handles, labels, bbox_to_anchor=(0.5, 0.486, 0.5, 0.5), fontsize=legendsize, fancybox=True, markerscale=2.) #, framealpha=1)\n",
    "    \n",
    "    axis[4].set_ylim(0, 600)\n",
    "\n",
    "    # add a ledgent to the last plot\n",
    "    legend = axis[4].legend(loc=\"upper right\", fontsize=legendsize, markerscale=2.)\n",
    "    # add axis labels to the last plot\n",
    "    axis[4].set_xlabel(\"Time (sec)\", fontsize=labelsize, fontname=fname)\n",
    "    axis[4].set_ylabel(\"Veloctiy\", fontsize=labelsize, fontname=fname)\n",
    "    # the the ticksize and font of the last plot\n",
    "    for label in axis[4].get_xticklabels():\n",
    "        label.set_fontproperties(fname)\n",
    "    for label in axis[4].get_yticklabels():\n",
    "        label.set_fontproperties(fname)\n",
    "    axis[4].yaxis.set_tick_params(labelsize=ticksize)  # change tick size\n",
    "    axis[4].xaxis.set_tick_params(labelsize=ticksize)\n",
    "\n",
    "    # plot labels\n",
    "    axis[0].set_title(\"A\", fontsize=numbersize, fontweight=\"bold\",loc=\"left\", x=-0.08, y=1.05, pad=-30, fontname=fname)\n",
    "    axis[2].set_title(\"B\", fontsize=numbersize, fontweight=\"bold\",loc=\"left\", x=-0.08, y=1.05, pad=-30, fontname=fname)\n",
    "    axis[4].set_title(\"C\", fontsize=numbersize, fontweight=\"bold\",loc=\"left\", x=-0.08, y=1.05, pad=-30, fontname=fname)\n",
    "    \n",
    "    \n",
    "    ####### Add boxes ########\n",
    "    y_up, y_down = axis[0].get_ylim(), axis[4].get_ylim() # mind and max y-limit\n",
    "    \n",
    "    # blue square:\n",
    "    axis[0].hlines(max(y_up), 647.6, 647.65, linewidth=5, color=gaze_color_1)\n",
    "    axis[4].hlines(min(y_down)+20, 647.6, 647.65, linewidth=5, color=gaze_color_1)\n",
    "    line1 = ConnectionPatch(xyA=[647.6,min(y_down)+20], xyB=[647.6,max(y_up)], coordsA=\"data\", coordsB=\"data\",\n",
    "                          axesA= axis[4], axesB=axis[0], color=gaze_color_1, lw=5,zorder=2)\n",
    "    line2 = ConnectionPatch(xyA=[647.65,min(y_down)+20], xyB=[647.65,max(y_up)], coordsA=\"data\", coordsB=\"data\",\n",
    "                          axesA= axis[4], axesB=axis[0], color=gaze_color_1, lw=5,zorder=2)\n",
    "    axis[4].add_artist(line1)\n",
    "    axis[4].add_artist(line2)\n",
    "\n",
    "    # red square:\n",
    "    axis[0].hlines(max(y_up), 648.3, 648.5, linewidth=5, color=sacc_color_1)\n",
    "    axis[4].hlines(min(y_down)+20, 648.3, 648.5, linewidth=5, color=sacc_color_1)\n",
    "    line1 = ConnectionPatch(xyA=[648.3,min(y_down)+20], xyB=[648.3,max(y_up)], coordsA=\"data\", coordsB=\"data\",\n",
    "                          axesA= axis[4], axesB=axis[0], color=sacc_color_1, lw=5,zorder=2)\n",
    "    line2 = ConnectionPatch(xyA=[648.5,min(y_down)+20], xyB=[648.5,max(y_up)], coordsA=\"data\", coordsB=\"data\",\n",
    "                          axesA= axis[4], axesB=axis[0], color=sacc_color_1, lw=5,zorder=2)\n",
    "    axis[4].add_artist(line1)\n",
    "    axis[4].add_artist(line2)\n",
    "    \n",
    "    # green square:\n",
    "    y_down1 =  axis[1].get_ylim()\n",
    "    axis[0].hlines(max(y_up), 648.85, 648.9, linewidth=5, color=vel_eye_color)\n",
    "    axis[1].hlines(min(y_down1)+5, 648.85, 648.9, linewidth=5, color=vel_eye_color)\n",
    "    line1 = ConnectionPatch(xyA=[648.85,min(y_down1)+5], xyB=[648.85,max(y_up)], coordsA=\"data\", coordsB=\"data\",\n",
    "                          axesA= axis[1], axesB=axis[0], color=vel_eye_color, lw=5,zorder=3)\n",
    "    line2 = ConnectionPatch(xyA=[648.9,min(y_down1)+5], xyB=[648.9,max(y_up)], coordsA=\"data\", coordsB=\"data\",\n",
    "                          axesA= axis[1], axesB=axis[0], color=vel_eye_color, lw=5,zorder=3)\n",
    "    axis[1].add_artist(line1)\n",
    "    axis[1].add_artist(line2)\n",
    "\n",
    "\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d981a459-20af-4aaf-ad04-edf8a9445afe",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Eye and Head Movements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c743685-adf3-4c10-985c-b2c9702329c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Compare if there is a statistical significant difference \n",
    "between distance of gaze and saccade \n",
    "This code is only  for the data-driven interval \n",
    "'''\n",
    "\n",
    "ids = recordings.index.tolist()\n",
    "idd = ids[:]\n",
    "\n",
    "gze = [] # save median gaze distance of each subject\n",
    "sac = [] # save median saccade distance of each subject\n",
    "for uid in idd:\n",
    "    for_eye = pd.read_csv(\n",
    "        f\"{PATH_FOREYE}/correTS_mad_wobig_{uid}.csv\", index_col=0\n",
    "    )\n",
    "\n",
    "    # separate between gaze and saccade\n",
    "    sacc = for_eye[for_eye[\"events\"] == 1.0]\n",
    "    # exclude long events\n",
    "    sacc = sacc[~sacc[\"long_events\"].isnull()]\n",
    "    # add median saccade distance\n",
    "    sac.append(np.nanmedian(sacc[\"avg_dist\"]))\n",
    "\n",
    "    # separate between gaze and saccade\n",
    "    gaze = for_eye[for_eye[\"events\"] == 2.0]\n",
    "    # exclude long events\n",
    "    gaze = gaze[~gaze[\"long_events\"].isnull()]\n",
    "    # add median gaze distance\n",
    "    gze.append(np.nanmedian(gaze[\"avg_dist\"]))\n",
    "\n",
    "print(\"data-driven interval\")\n",
    "# as they are not completely normally distributed, we will use median to get the average results:\n",
    "med_gaze = np.nanmedian(gze)\n",
    "med_sacc = np.nanmedian(sac)\n",
    "print(f\"Median gaze distance: {med_gaze}\")\n",
    "print(f\"Median sacc distance: {med_sacc}\")\n",
    "# Interquartile range:\n",
    "q75_g, q25_g = np.nanpercentile(gze, [75, 25])\n",
    "iqr_gaze = q75_g - q25_g\n",
    "q75_s, q25_s = np.nanpercentile(sac, [75, 25])\n",
    "iqr_sacc = q75_s - q25_s\n",
    "print(f\"IQR gaze distance: {iqr_gaze} ({q25_g}-{q75_g})\")\n",
    "print(f\"IQR sacc distance: {iqr_sacc} ({q25_s}-{q75_s})\")\n",
    "\n",
    "# Perform the KS test\n",
    "print()\n",
    "statistic, pvalue = ks_2samp(gze, sac)\n",
    "print(f\"KS statistic: {statistic:.4f}\")\n",
    "print(f\"P-value: {pvalue:.4f}\")\n",
    "alpha = 0.05\n",
    "print(f\"Alpha: {alpha:.4f}\")\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4deaf7-b016-4dd8-abb7-ed7fdd955dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calcualte the saccade amplitude\n",
    "def compute_centroid(df, columns):\n",
    "    '''\n",
    "    Computes the mean of the columns of a df.\n",
    "    \n",
    "    Parameters:\n",
    "        df: the df to compute the mean of\n",
    "        columns: column names of the column's to computer the mean of\n",
    "    '''\n",
    "    centroid = df[columns].mean().values\n",
    "    return centroid\n",
    "\n",
    "def compute_saccade_amplitude(prev_gaze_centroid, prev_subject_centroid, gaze_centroid, subject_centroid):\n",
    "    '''\n",
    "    Compute the saccade amplitude while correcting for translational movement.\n",
    "    \n",
    "    Parameters:\n",
    "        prev_gaze_centroid: the previous mean hit position\n",
    "        prev_subject_centroid: the previous mean eye position\n",
    "        gaze_centroid: the current mean hit position\n",
    "        subject_centroid: the current mean eye position\n",
    "    '''\n",
    "    v_eye_vec = gaze_centroid - prev_gaze_centroid \n",
    "    eye_vec = prev_gaze_centroid - prev_subject_centroid\n",
    "    eye_vec = eye_vec/np.linalg.norm(eye_vec)\n",
    "    projection = np.dot(v_eye_vec, eye_vec) * eye_vec\n",
    "    v_eye_inplane = np.linalg.norm(v_eye_vec - projection)\n",
    "    sacc_amplitude = np.arctan2(v_eye_inplane, np.linalg.norm(prev_subject_centroid - prev_gaze_centroid))\n",
    "    return np.degrees(sacc_amplitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4b5ec8-f95e-4a06-9528-456bf0fc9f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Plot the eye and head movements, position and distance.\n",
    "'''\n",
    "ids = recordings.index.tolist()\n",
    "idd = ids[:1]\n",
    "gze = []\n",
    "sac = []\n",
    "cnt = 0 # to adjust line style for the distance plot\n",
    "# used for the position plot\n",
    "min_x = 505\n",
    "max_x = 642\n",
    "min_y = 519\n",
    "max_y = 655\n",
    "\n",
    "# set plotting parameters for:\n",
    "labelsize = 40 # text\n",
    "legendsize = 40 # ledgend\n",
    "ticksize = 30 # ticks\n",
    "numbersize = 60 # A, B etc.\n",
    "fname = \"Arial\" # font name\n",
    "\n",
    "plt.figure(figsize=(32, 32), constrained_layout=True)\n",
    "\n",
    "sns.set_style(\"white\") \n",
    "plt.rcParams[\"font.family\"] = fname\n",
    "# define figure grid\n",
    "ax11 = plt.subplot2grid(shape=(6, 6), loc=(0, 0), rowspan=2, colspan=2)\n",
    "ax12 = plt.subplot2grid(shape=(6, 6), loc=(0, 2), rowspan=2, colspan=2)\n",
    "ax13 = plt.subplot2grid(shape=(6, 6), loc=(0, 4), rowspan=2, colspan=2)\n",
    "ax21 = plt.subplot2grid(shape=(6, 6), loc=(2, 0), rowspan=2, colspan=2)\n",
    "ax22 = plt.subplot2grid(shape=(6, 6), loc=(2, 2), rowspan=2, colspan=2)\n",
    "ax23 = plt.subplot2grid(shape=(6, 6), loc=(2, 4), rowspan=2, colspan=2)\n",
    "ax5 = plt.subplot2grid(shape=(6, 6), loc=(4, 0), rowspan=2, colspan=2)\n",
    "ax3 = plt.subplot2grid(shape=(6, 6), loc=(4, 2), rowspan=2, colspan=2)\n",
    "ax4 = plt.subplot2grid(shape=(6, 6), loc=(4, 4), rowspan=2, colspan=2)\n",
    "# ensure that the first 6 plots are all squares\n",
    "ax11.set_aspect(1.0/ax11.get_data_ratio(), adjustable='box')\n",
    "ax12.set_aspect(1.0/ax12.get_data_ratio(), adjustable='box')\n",
    "ax13.set_aspect(1.0/ax13.get_data_ratio(), adjustable='box')\n",
    "ax21.set_aspect(1.0/ax11.get_data_ratio(), adjustable='box')\n",
    "ax22.set_aspect(1.0/ax12.get_data_ratio(), adjustable='box')\n",
    "ax23.set_aspect(1.0/ax13.get_data_ratio(), adjustable='box')\n",
    "\n",
    "\n",
    "####### Gazes in Space #######\n",
    "# plot the background image (bird-eye-view of the city center)\n",
    "img = plt.imread(\"unity_scene_bird_quad.png\")\n",
    "ax4.imshow(img, extent=[min_x, max_x, min_y, max_y])\n",
    "# define window and axis\n",
    "ax4.set_xlim(min_x, max_x)\n",
    "ax4.set_ylim(min_y, max_y)\n",
    "ax4.set_xticks([])\n",
    "ax4.set_yticks([])\n",
    "ax4.set_title(\"G\", fontsize=numbersize, fontweight=\"bold\",loc=\"left\", x=-0.09, y=1.05, pad=-30, fontname=fname)\n",
    "\n",
    "min_x = 505\n",
    "max_x = 642\n",
    "min_y = 519\n",
    "max_y = 657\n",
    "\n",
    "# plot the red outline:\n",
    "# this was done manually, the points are in relation to the window of the plot (so how much one zooms in)\n",
    "trianglex = [516, 610.75, 610.75, 630, 630, 612.6, 614.8, 578,   563,   559,   \n",
    "             556,   550,   545,   541, 538,   535, 529, 526,   527, 516, 516] \n",
    "triangley = [565, 565,    555,    555, 621, 621,   611.5, 611.5, 609.5, 608.8, \n",
    "             608.5, 607.9, 607.8, 608, 608.5, 609.0, 611.0, 612.5, 621, 621, 565]\n",
    "for i in range(3):\n",
    "    plt.plot( trianglex, triangley, color=sacc_color_1, linestyle='-', linewidth=4)\n",
    "\n",
    "    \n",
    "### Add the data from all subjects\n",
    "amplitude = []\n",
    "peak_vel = []\n",
    "# loop through all subjects\n",
    "for i, uid in enumerate(idd):\n",
    "    # load data:\n",
    "    for_eye = pd.read_csv(f\"{PATH_FOREYE}/correTS_mad_wobig_{uid}.csv\", index_col=0)\n",
    "    \n",
    "    ####### Direction Vectors World #######\n",
    "    # eye position\n",
    "    Xcorr_position = for_eye[\"xcoord_orig\"].tolist()\n",
    "    Ycorr_position = for_eye[\"ycoord_orig\"].tolist()\n",
    "    Zcorr_position = for_eye[\"zcoord_orig\"].tolist()\n",
    "    subj = list(zip(Xcorr_position, Ycorr_position, Zcorr_position))\n",
    "    # hit position\n",
    "    hpooX = for_eye[\"xhpoo\"].tolist()\n",
    "    hpooY = for_eye[\"yhpoo\"].tolist()\n",
    "    hpooZ = for_eye[\"zhpoo\"].tolist()\n",
    "    hpoo = list(zip(hpooX, hpooY, hpooZ))\n",
    "    # gaze_vec(t) is a unit vector in the direction of the gaze (eye+head) in world coordinates\n",
    "    g_vec = [np.array(hpoo[v] - np.array(subj[v])) for v in range(len(subj))]\n",
    "    gaze_vec = [np.array(v) / np.linalg.norm(np.array(v)) for v in g_vec]\n",
    "    # create df to plot\n",
    "    gaze_vec = pd.DataFrame(gaze_vec, columns=[\"gvx\", \"gvy\", \"gvz\"])\n",
    "    # add it to for_eye so we can differentiate between gaze and saccade\n",
    "    for_eye_new = pd.concat([for_eye, gaze_vec], axis=1)\n",
    "    # separate between gaze and saccade\n",
    "    gaze = for_eye_new[~for_eye_new[\"isFix\"].isnull()]\n",
    "    sacc = for_eye_new[for_eye_new[\"isFix\"].isnull()]\n",
    "    gaze = gaze[~gaze[\"long_events\"].isnull()]\n",
    "    sacc = sacc[~sacc[\"long_events\"].isnull()]\n",
    "    # create three plots as we have 3 coordinates\n",
    "    # X vs Y\n",
    "    ax11.scatter(gaze[\"gvx\"].tolist(), gaze[\"gvy\"].tolist(), color =gaze_color_1,s=4,edgecolors='none', alpha=0.04)\n",
    "    # Z vs Y\n",
    "    ax12.scatter(gaze[\"gvz\"].tolist(), gaze[\"gvy\"].tolist(), color =gaze_color_1,s=4,edgecolors='none', alpha=0.04)\n",
    "    # X vs Z\n",
    "    ax13.scatter(gaze[\"gvx\"].tolist(), gaze[\"gvz\"].tolist(), color =gaze_color_1,s=4,edgecolors='none', alpha=0.04)\n",
    "    \n",
    "    \n",
    "    ####### Direction Vectors Local, Head, Saccade Vector #######\n",
    "    # separate between gaze and saccade\n",
    "    gaze = for_eye[~for_eye[\"isFix\"].isnull()]\n",
    "    gaze = gaze[~gaze[\"long_events\"].isnull()]\n",
    "    # get the saccade vectors: (difference between beginning and end of saccade)\n",
    "    # at first, define saccade onset and offset (correction needed in case the saccade is only one sample long)\n",
    "    events = [-1.0 if (for_eye[\"events\"][ev - 1] == 1.0 and for_eye[\"events\"][ev] == 2.0)\n",
    "        else for_eye[\"events\"][ev]\n",
    "        for ev in for_eye.index.tolist()[2:]\n",
    "    ]\n",
    "    events = [for_eye[\"events\"][0]] + [for_eye[\"events\"][1]]  + events\n",
    "    for_eye_new[\"events\"] = events\n",
    "    # get the saccade vectors: (diff between beginning and end of saccade)\n",
    "    sacc_start = for_eye_new[for_eye_new[\"events\"] == 1.0]\n",
    "    sacc_end = for_eye_new[for_eye_new[\"events\"] == -1.0]\n",
    "    # for one subject, the beginning is messed up, so correct it:\n",
    "    if sacc_end.index[0] < sacc_start.index[0]:\n",
    "        sacc_end = sacc_end[1:]\n",
    "    # separate saccades\n",
    "    sacc = for_eye_new[for_eye_new[\"isFix\"].isnull()]\n",
    "    # now get the diff between beginning and end\n",
    "    sacc_x = (\n",
    "        np.array(sacc_start[\"xcoord\"].tolist())\n",
    "        - np.array(sacc_end[\"xcoord\"].tolist())\n",
    "    ).tolist()\n",
    "    sacc_y = (\n",
    "        np.array(sacc_start[\"ycoord\"].tolist())\n",
    "        - np.array(sacc_end[\"ycoord\"].tolist())\n",
    "    ).tolist()\n",
    "    sacc_z = (\n",
    "        np.array(sacc_start[\"zcoord\"].tolist())\n",
    "        - np.array(sacc_end[\"zcoord\"].tolist())\n",
    "    ).tolist()\n",
    "    sacc_v = list(zip(sacc_x, sacc_y, sacc_z))\n",
    "    sacc_v_norm = [np.array(v) / np.linalg.norm(np.array(v)) for v in sacc_v]\n",
    "    sacc_v_norm_df = pd.DataFrame(sacc_v_norm, columns = ['x', 'y', 'z'])\n",
    "    # Head: plot the x vs y coordiante \n",
    "    ax21.scatter(gaze[\"xhead\"].tolist(), gaze[\"yhead\"].tolist(), color =gaze_color_1,s=4,edgecolors='none', alpha=0.04)\n",
    "    # local eye-tracking data: plot the local eye-in-head direction vector\n",
    "    ax22.scatter(gaze[\"xlocal_dir\"].tolist(), gaze[\"ylocal_dir\"].tolist(), color =gaze_color_1,s=4,edgecolors='none', alpha=0.04)\n",
    "    # sacc vectors: plot them\n",
    "    for mk in range(len(sacc_x)):\n",
    "        ax23.plot([0, sacc_x[mk]], [0, sacc_y[mk]], sacc_color_1, alpha=0.15)\n",
    "\n",
    "    \n",
    "    \n",
    "    ####### Sacc Amp vs. Peak Vel #######\n",
    "    # --- SACCADE AMPLITUDE ---\n",
    "    prev_gaze_centroid = None\n",
    "    prev_subject_centroid = None\n",
    "    for_eye['saccade_amplitude'] = np.nan # create a row in the df with nans\n",
    "    # get the event onsets and offsets\n",
    "    start_indices = for_eye[for_eye['events'] == 2.0].index\n",
    "    end_indices = for_eye[for_eye['events'] == -2.0].index\n",
    "    start_sacc = for_eye[for_eye['events'] == 1.0].index # get the start of saccades to appropriately add the saccade amplitudes to the conditions\n",
    "    # correct for two cases:\n",
    "    # check if first start_sacc is smaller than first start_indices --> if not, add the first start_indices to the start_sacc list\n",
    "    if start_sacc[0] > start_indices[0]:\n",
    "        start_sacc = [start_indices[0]] + start_sacc\n",
    "    # if the last start_sacc is bigger than the last start_indices --> remove it\n",
    "    if start_sacc[-1] > start_indices[-1]:\n",
    "        start_sacc = start_sacc[:-1]\n",
    "    if len(end_indices) > len(start_indices):\n",
    "        # in case there has been an end index without a start one, get rid of this\n",
    "        if end_indices[0] < start_indices[0]:\n",
    "            end_indices = end_indices[1:]\n",
    "        else: \n",
    "            print(uid)\n",
    "    # loop through all events\n",
    "    for start, end, start_s in zip(start_indices, end_indices, start_sacc):\n",
    "        # get a smaller df\n",
    "        group_df = for_eye.loc[start:end]\n",
    "        # Compute the centroid of the gaze positions and the mean timestamp\n",
    "        gaze_centroid = compute_centroid(group_df, ['xhpoo', 'yhpoo', 'zhpoo'])\n",
    "        subject_centroid = compute_centroid(group_df, ['xcoord_orig', 'ycoord_orig', 'zcoord_orig'])\n",
    "        # Compute the saccade amplitude and store it in the dataframe\n",
    "        if prev_gaze_centroid is not None and prev_subject_centroid is not None:\n",
    "            for_eye.loc[start_s:end, 'saccade_amplitude'] = compute_saccade_amplitude(prev_gaze_centroid, prev_subject_centroid, gaze_centroid, subject_centroid)\n",
    "        # Update the previous centroids and timestamp\n",
    "        prev_gaze_centroid = gaze_centroid\n",
    "        prev_subject_centroid = subject_centroid\n",
    "    # --- SACCADE AMPLITUDE ---\n",
    "    # --- PEAK VELOCITY ---\n",
    "    # loop through all events\n",
    "    for start_s, start in zip(start_sacc, start_indices):\n",
    "        # get a small df\n",
    "        cur = for_eye.iloc[start_s : start-1]\n",
    "        # I expect to see RuntimeWarnings in this block\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "            # comput the maximum velocity\n",
    "            try:\n",
    "                for_eye.loc[start_s:start-1, 'peak_velocity'] = np.nanmax(cur[\"combined_vel\"].tolist())\n",
    "            except ValueError:\n",
    "                pass\n",
    "    # --- PEAK VELOCITY ---\n",
    "    # only take the saccade onsets, so we plot one datapoint per event\n",
    "    sacc = for_eye[for_eye[\"events\"] == 1.0]\n",
    "    sacc = sacc[~sacc[\"long_events\"].isnull()]\n",
    "    amplitude = amplitude + sacc['saccade_amplitude'].tolist()\n",
    "    peak_vel = peak_vel + sacc['peak_velocity'].tolist()\n",
    "    \n",
    "    \n",
    "    ####### Distance Distribution #######\n",
    "    # separate between gaze and saccade\n",
    "    sacc = for_eye[for_eye[\"events\"] == 1.0]\n",
    "    # exclude long events\n",
    "    sacc = sacc[~sacc[\"long_events\"].isnull()]\n",
    "    sacc.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    sac.append(np.nanmedian(sacc[\"avg_dist\"]))\n",
    "    # plot saccades\n",
    "    sns.kdeplot(\n",
    "        sacc[\"avg_dist\"],\n",
    "        color=sacc_color_1,\n",
    "        fill=False,\n",
    "        clip=[0, 100],\n",
    "        alpha=0.6,\n",
    "        label=\"Saccade Distance\",\n",
    "        ax = ax3\n",
    "    )\n",
    "    cnt = cnt + 1\n",
    "    # separate between gaze and saccade\n",
    "    gaze = for_eye[for_eye[\"events\"] == 2.0]\n",
    "    # exclude long events\n",
    "    gaze = gaze[~gaze[\"long_events\"].isnull()]\n",
    "    gze.append(np.nanmedian(gaze[\"avg_dist\"]))\n",
    "    # plot gazes\n",
    "    sns.kdeplot(\n",
    "        gaze[\"avg_dist\"],\n",
    "        color=gaze_color_1,\n",
    "        fill=False,\n",
    "        clip=[0, 100],\n",
    "        alpha=0.9,\n",
    "        label=\"Gaze Distance\",\n",
    "        ax = ax3\n",
    "    )\n",
    "    ax3.lines[cnt].set_linestyle(\"--\") # set the lnie style for gazes\n",
    "    cnt = cnt + 1\n",
    "    \n",
    "    \n",
    "    ####### Gazes in Space #######\n",
    "    # only get gazes without nans and wihtout long events\n",
    "    gaze = for_eye[for_eye[\"events\"] == 2.0]\n",
    "    gaze = gaze[~gaze[\"long_events\"].isnull()]  \n",
    "    # plot the hit points on top of the image displayed at the beginning of this cell\n",
    "    ax4 = plt.scatter(\n",
    "        x=gaze[\"xhpoo\"].tolist(),\n",
    "        y=gaze[\"zhpoo\"].tolist(),\n",
    "        color=\"k\",\n",
    "        marker=\".\",\n",
    "        alpha=0.2,\n",
    "        linewidth=0,\n",
    "    )  \n",
    "\n",
    "\n",
    "# Set axis styles:\n",
    "\n",
    "####### Direction Vectors World #######\n",
    "ax11.set_xlabel(\"X-Coordinates\", fontsize=labelsize, fontname=fname)\n",
    "ax11.set_ylabel(\"Y-Coordinates\", fontsize=labelsize, fontname=fname)\n",
    "for label in ax11.get_xticklabels(): # change tick font\n",
    "    label.set_fontproperties(fname)\n",
    "for label in ax11.get_yticklabels():\n",
    "    label.set_fontproperties(fname)\n",
    "ax11.yaxis.set_tick_params(labelsize=ticksize)  # change tick size\n",
    "ax11.xaxis.set_tick_params(labelsize=ticksize)\n",
    "ax11.set_xticks([-1, 0, 1])\n",
    "ax11.set_yticks([-1, 0, 1])\n",
    "ax11.set_xlim(-1.1, 1.1)\n",
    "ax11.set_ylim(-1.1, 1.1)\n",
    "ax11.set_xticks(np.linspace(-1.0, 1.0, num=3))\n",
    "\n",
    "# Z vs Y\n",
    "ax12.set_xlabel(\"Z-Coordinates\", fontsize=labelsize, fontname=fname)\n",
    "ax12.set_ylabel(\"Y-Coordinates\", fontsize=labelsize, fontname=fname)\n",
    "for label in ax12.get_xticklabels(): # change tick font\n",
    "    label.set_fontproperties(fname)\n",
    "for label in ax12.get_yticklabels():\n",
    "    label.set_fontproperties(fname)\n",
    "ax12.yaxis.set_tick_params(labelsize=ticksize)  # change tick size\n",
    "ax12.xaxis.set_tick_params(labelsize=ticksize)\n",
    "ax12.set_xticks([-1, 0, 1])\n",
    "ax12.set_yticks([-1, 0, 1])\n",
    "ax12.set_xlim(-1.1, 1.1)\n",
    "ax12.set_ylim(-1.1, 1.1)\n",
    "\n",
    "# X vs Z\n",
    "ax13.set_xlabel(\"X-Coordinates\", fontsize=labelsize, fontname=fname)\n",
    "ax13.set_ylabel(\"Z-Coordinates\", fontsize=labelsize, fontname=fname)\n",
    "for label in ax13.get_xticklabels(): # change tick font\n",
    "    label.set_fontproperties(fname)\n",
    "for label in ax13.get_yticklabels():\n",
    "    label.set_fontproperties(fname)\n",
    "ax13.yaxis.set_tick_params(labelsize=ticksize)  # change tick size\n",
    "ax13.xaxis.set_tick_params(labelsize=ticksize)\n",
    "ax13.set_xticks([-2, -1, 0, 1, 2])\n",
    "ax13.set_yticks([-2, -1, 0, 1, 2])\n",
    "ax13.set_xlim(-1.1, 1.1)\n",
    "ax13.set_ylim(-1.1, 1.1)\n",
    " \n",
    "####### Direction Vectors Local, Head, Saccade Vector #######\n",
    "# Head\n",
    "ax21.set_xlabel(\"X-Coordinates\", fontsize=labelsize, fontname=fname)\n",
    "ax21.set_ylabel(\"Y-Coordinates\", fontsize=labelsize, fontname=fname)\n",
    "for label in ax21.get_xticklabels(): # change tick font\n",
    "    label.set_fontproperties(fname)\n",
    "for label in ax21.get_yticklabels():\n",
    "    label.set_fontproperties(fname)\n",
    "ax21.set_xticks([-1, 0, 1])\n",
    "ax21.set_yticks([-1, 0, 1])\n",
    "ax21.yaxis.set_tick_params(labelsize=ticksize)  # change tick size\n",
    "ax21.xaxis.set_tick_params(labelsize=ticksize)\n",
    "ax21.set_xlim(-1.1, 1.1)\n",
    "ax21.set_ylim(-1.1, 1.1)\n",
    "# Local ET\n",
    "ax22.set_xlabel(\"X-Coordinates\", fontsize=labelsize, fontname=fname)\n",
    "ax22.set_ylabel(\"Y-Coordinates\", fontsize=labelsize, fontname=fname)\n",
    "for label in ax22.get_xticklabels(): # change tick font\n",
    "    label.set_fontproperties(fname)\n",
    "for label in ax22.get_yticklabels():\n",
    "    label.set_fontproperties(fname)\n",
    "ax22.yaxis.set_tick_params(labelsize=ticksize)  # change tick size\n",
    "ax22.xaxis.set_tick_params(labelsize=ticksize)\n",
    "ax22.set_xticks([-2, -1, 0, 1, 2])\n",
    "ax22.set_yticks([-2, -1, 0, 1, 2])\n",
    "ax22.set_xlim(-1.1, 1.1)\n",
    "ax22.set_ylim(-1.1, 1.1)\n",
    "# Sacc Vector\n",
    "ax23.set_xlabel(\"X-Coordinates\", fontsize=labelsize, fontname=fname)\n",
    "ax23.set_ylabel(\"Y-Coordinates\", fontsize=labelsize, fontname=fname)\n",
    "for label in ax23.get_xticklabels(): # change tick font\n",
    "    label.set_fontproperties(fname)\n",
    "for label in ax23.get_yticklabels():\n",
    "    label.set_fontproperties(fname)\n",
    "ax23.yaxis.set_tick_params(labelsize=ticksize)  # change tick size\n",
    "ax23.xaxis.set_tick_params(labelsize=ticksize)\n",
    "ax23.set_xticks([-2, -1, 0, 1, 2])\n",
    "ax23.set_yticks([-2, -1, 0, 1, 2])\n",
    "ax23.set_xlim(-1.1, 1.1)\n",
    "ax23.set_ylim(-1.1, 1.1)\n",
    "\n",
    "    \n",
    "####### Sacc Amp vs. Peak Vel #######\n",
    "# plot it against each other\n",
    "stats = {}\n",
    "stats[\"saccade_amplitude\"] = amplitude\n",
    "stats[\"peak_velocity\"] = peak_vel\n",
    "stats = pd.DataFrame(stats)\n",
    "sns.scatterplot(data=stats,x = \"saccade_amplitude\", y = \"peak_velocity\",ax=ax5,marker=\"x\", color=sacc_color_1,alpha = 0.3)\n",
    "ax5.set_xlabel(\"Saccade Amplitude (deg)\", fontsize=labelsize)\n",
    "ax5.set_ylabel(\"Peak Velocity (deg/s)\", fontsize=labelsize)\n",
    "for label in ax5.get_xticklabels(): # change tick font\n",
    "    label.set_fontproperties(fname)\n",
    "for label in ax5.get_yticklabels():\n",
    "    label.set_fontproperties(fname)\n",
    "ax5.xaxis.set_tick_params(labelsize=ticksize)  # change tick size\n",
    "ax5.yaxis.set_tick_params(labelsize=ticksize)  # change tick size\n",
    "ax5.set_xlim([-1, 43])\n",
    "ax5.set_ylim([-30, 900])\n",
    "ax5.set_xticks([0,10,20,30,40]) \n",
    "    \n",
    "####### Distance Distribution #######\n",
    "# plot the ledgend\n",
    "handles, labels = ax3.get_legend_handles_labels()\n",
    "leg = ax3.legend(\n",
    "    [handles[0], handles[-1]],\n",
    "    [labels[0], labels[-1]],\n",
    "    loc=\"upper right\",\n",
    "    fontsize=legendsize,\n",
    ")\n",
    "# set alpha of ledgend symbols to 1\n",
    "for lh in leg.legendHandles:\n",
    "    lh.set_alpha(1)\n",
    "ax3.set_xlabel(\"Distance (in Unity Units)\", fontsize=labelsize, fontname=fname)\n",
    "ax3.set_ylabel(\"Density of Distances\", fontsize=labelsize, fontname=fname)\n",
    "for label in ax3.get_xticklabels(): # change tick font\n",
    "    label.set_fontproperties(fname)\n",
    "for label in ax3.get_yticklabels():\n",
    "    label.set_fontproperties(fname)\n",
    "ax3.yaxis.set_tick_params(labelsize=ticksize)  # change tick size\n",
    "ax3.xaxis.set_tick_params(labelsize=ticksize)\n",
    "ax3.set_yticks([0.01,0.03,0.05]) \n",
    "ax3.locator_params(nbins=6, axis='y')\n",
    "\n",
    "ax11.set_title(\"A\", fontsize=numbersize, fontweight=\"bold\",loc=\"left\", x=-0.1, y=1.05, pad=-30, fontname=fname)\n",
    "ax21.set_title(\"B\", fontsize=numbersize, fontweight=\"bold\",loc=\"left\", x=-0.1, y=1.05, pad=-30, fontname=fname)\n",
    "ax22.set_title(\"C\", fontsize=numbersize, fontweight=\"bold\",loc=\"left\", x=-0.1, y=1.05, pad=-30, fontname=fname)\n",
    "ax23.set_title(\"D\", fontsize=numbersize, fontweight=\"bold\",loc=\"left\", x=-0.1, y=1.05, pad=-30, fontname=fname)\n",
    "ax5.set_title(\"E\", fontsize=numbersize, fontweight=\"bold\",loc=\"left\", x=-0.1, y=1.05, pad=-30, fontname=fname)\n",
    "ax3.set_title(\"F\", fontsize=numbersize, fontweight=\"bold\",loc=\"left\", x=-0.1, y=1.05, pad=-30, fontname=fname)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "##### Stats Saccade Amplitude vs. Peak Vel.\n",
    "# calculate the correlation between sacc amplitude and peak velocity\n",
    "# drop rows that contain NaN values for the statistics\n",
    "stats = stats.dropna()\n",
    "r, p = scipy.stats.pearsonr(stats[\"saccade_amplitude\"], stats[\"peak_velocity\"])\n",
    "print(f\"statistic: {r}\")\n",
    "print(f\"pvalue: {round(p,3)}\")\n",
    "print(f\"degress of freedom : {len(stats) - 2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdca5f8-c069-48da-b724-97efdf5c0ca1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##### Get the max for the local eye-in-head direction vectors (for x and y)\n",
    "ids = recordings.index.tolist()\n",
    "idd = ids[:]\n",
    "\n",
    "max_x = [] # to add the data for each subject\n",
    "max_y = []\n",
    "\n",
    "for i, uid in enumerate(idd):\n",
    "    # load data\n",
    "    for_eye = pd.read_csv(\n",
    "        f\"{PATH_FOREYE}/correTS_mad_wobig_{uid}.csv\", index_col=0\n",
    "    )\n",
    "    gaze = for_eye[~for_eye[\"isFix\"].isnull()]\n",
    "    gaze = gaze[~gaze[\"long_events\"].isnull()]\n",
    "\n",
    "    # we don't care about the sign, just the absolute value\n",
    "    abs_x = [abs(ele) for ele in gaze[\"xlocal_dir\"].tolist()]\n",
    "    abs_y = [abs(ele) for ele in gaze[\"ylocal_dir\"].tolist()]\n",
    "    # add the maximum of each subejct\n",
    "    max_x = max_x + [np.nanmax(abs_x)]\n",
    "    max_y = max_y + [np.nanmax(abs_y)]\n",
    "\n",
    "columns=['max_x','max_y']\n",
    "df = pd.DataFrame(list(zip(max_x,max_y)),columns=columns,index=idd)\n",
    "# give an overview over the data\n",
    "display(df.describe())\n",
    "print()\n",
    "# calculate a t-test between the maximum dimensions\n",
    "scipy.stats.ttest_rel(max_x,max_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5c63d5-f16e-448b-b5fe-0cca6a3838d1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Data Distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb86ff7-6740-4cfa-a409-8a2e733bec54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "''' Calculate and compare the number of events for gazes and saccades.\n",
    "This is done for both, the 10-second and data-driven method.\n",
    "'''\n",
    "ids = recordings.index.tolist()\n",
    "idd = ids[:]\n",
    "\n",
    "stats = {} # df to collect the amount of events\n",
    "\n",
    "for uid in idd:\n",
    "    stats[uid] = {}\n",
    "    for fe in range(2):\n",
    "        # load data\n",
    "        # 10 sec\n",
    "        if fe == 0:\n",
    "            for_eye = pd.read_csv(\n",
    "                f\"{PATH_FOREYE}/correTS__10sec_{uid}.csv\", index_col=0\n",
    "            )\n",
    "            condition = \"10\"\n",
    "        else:\n",
    "            for_eye = pd.read_csv(\n",
    "                f\"{PATH_FOREYE}/correTS_mad_wobig_{uid}.csv\", index_col=0\n",
    "            )\n",
    "            condition = \"dd\"\n",
    "\n",
    "        # get gazes, but not outliers\n",
    "        gaze = for_eye[for_eye[\"events\"] == 2.0]\n",
    "        gaze = gaze[~gaze[\"long_events\"].isnull()]\n",
    "\n",
    "        # get saccades but not outliers\n",
    "        sacc = for_eye[for_eye[\"events\"] == 1.0]\n",
    "        sacc = sacc[~sacc[\"long_events\"].isnull()]\n",
    "\n",
    "        # save the number of events\n",
    "        stats[uid][condition + \"_gaze\"] = gaze.index.size\n",
    "        stats[uid][condition + \"_sacc\"] = sacc.index.size\n",
    "\n",
    "stats = pd.DataFrame(stats).transpose()\n",
    "print()\n",
    "print(\"Number of Events:\")\n",
    "print()\n",
    "\n",
    "# print the median number of events\n",
    "print(f\"Median Gaze DD: {np.nanmedian(stats['dd_gaze'])}\")\n",
    "print(f\"Median Gaze 10: {np.nanmedian(stats['10_gaze'])}\")\n",
    "print(f\"Median Sacc DD: {np.nanmedian(stats['dd_sacc'])}\")\n",
    "print(f\"Median Sacc 10: {np.nanmedian(stats['10_sacc'])}\")\n",
    "print()\n",
    "\n",
    "# Interquartile range:\n",
    "q75, q25 = np.nanpercentile(stats['dd_gaze'].tolist(), [75, 25])\n",
    "iqr_gaze_dd = q75 - q25\n",
    "print(f\"IQR gaze DD: {iqr_gaze_dd} ({q25}-{q75})\")\n",
    "\n",
    "q75, q25 = np.nanpercentile(stats['dd_sacc'].tolist(), [75, 25])\n",
    "iqr_sacc_dd = q75 - q25\n",
    "print(f\"IQR sacc DD: {iqr_sacc_dd} ({q25}-{q75})\")\n",
    "\n",
    "q75_g, q25 = np.nanpercentile(stats['10_gaze'].tolist(), [75, 25])\n",
    "iqr_gaze_10 = q75 - q25\n",
    "print(f\"IQR gaze 10: {iqr_gaze_10} ({q25}-{q75})\")\n",
    "\n",
    "q75, q25 = np.nanpercentile(stats['10_sacc'].tolist(), [75, 25])\n",
    "iqr_sacc_10 = q75 - q25\n",
    "print(f\"IQR sacc 10: {iqr_sacc_10} ({q25}-{q75})\")\n",
    "print()\n",
    "\n",
    "# KS-tests\n",
    "print()\n",
    "print('KS-Test')\n",
    "alpha = 0.05\n",
    "adjusted_alpha = alpha / 4  # muultiple tests were performed\n",
    "print(f\"Adjusted alpha: {adjusted_alpha:.4f}\")\n",
    "print()\n",
    "\n",
    "statistic, p1 = ks_2samp(stats['10_gaze'].tolist(), stats['dd_gaze'].tolist())\n",
    "print(f\"p-value gaze: {p1:.4f}\")\n",
    "statistic, p2 = ks_2samp(stats['10_sacc'].tolist(), stats['dd_sacc'].tolist())\n",
    "print(f\"p-value sacc: {p2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eff3560-5abf-410b-aac3-f126b4fa1643",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "''' \n",
    "Plot the number of gazes, saccades, long events (outliers) and invalid data\n",
    "One datapoint will be one participant.\n",
    "We show the data for both data segmentation intervals.\n",
    "'''\n",
    "\n",
    "ids = recordings.index.tolist()\n",
    "idd = ids[:2]\n",
    "\n",
    "# set up figure\n",
    "sns.set(rc={\"figure.figsize\": (30, 15)})\n",
    "sns.set_style(\n",
    "    \"white\"\n",
    ") \n",
    "f, (ax) = plt.subplots(1, 2, sharey=True, constrained_layout=True)\n",
    "\n",
    "# define \n",
    "labelsize = 40 # text\n",
    "legendsize = 40 # ledgend\n",
    "ticksize = 30 # ticks\n",
    "numbersize = 60 # A, B etc.\n",
    "fname = \"Arial\" # font name\n",
    "plt.rcParams[\"font.family\"] = fname # set font name\n",
    "\n",
    "# go through both data segmentation intervals\n",
    "for fe in range(2):\n",
    "    # lists to save the data from every subject\n",
    "    nr_gaze = []\n",
    "    nr_sacc = []\n",
    "    nr_gz_out = []\n",
    "    nr_sc_out = []\n",
    "    non_val = []\n",
    "    total_nr = []\n",
    "    stats = {} # df for the results\n",
    "    # loop through all subjects (once per segmentation method)\n",
    "    for uid in idd:\n",
    "        # load data\n",
    "        # 10 sec\n",
    "        if fe == 0:\n",
    "            for_eye = pd.read_csv(\n",
    "                f\"{PATH_FOREYE}/correTS__10sec_{uid}.csv\", index_col=0\n",
    "            )\n",
    "        else:\n",
    "            for_eye = pd.read_csv(\n",
    "                f\"{PATH_FOREYE}/correTS_mad_wobig_{uid}.csv\", index_col=0\n",
    "            )\n",
    "\n",
    "        # get the total duration\n",
    "        total = for_eye.index.size\n",
    "\n",
    "        # get the number of invalid datapoints\n",
    "        outbig = for_eye[for_eye[\"valid\"] == 0.0]\n",
    "        for_eye = for_eye[for_eye[\"valid\"] == 1.0]\n",
    "\n",
    "        # for all valid datapoints, separate the data between gaze and saccade\n",
    "        gaze = for_eye[~for_eye[\"isFix\"].isnull()]\n",
    "        sacc = for_eye[for_eye[\"isFix\"].isnull()]\n",
    "\n",
    "        # further, separate gazes and saccades between outliers and valid events\n",
    "        gaze_out = gaze[gaze[\"long_events\"].isnull()]\n",
    "        sacc_out = sacc[sacc[\"long_events\"].isnull()]\n",
    "        gaze = gaze[~gaze[\"long_events\"].isnull()]\n",
    "        sacc = sacc[~sacc[\"long_events\"].isnull()]\n",
    "\n",
    "        # now calculate the percentage for each category\n",
    "        nr_gaze = nr_gaze + [gaze.index.size * 100 / total]\n",
    "        nr_sacc = nr_sacc + [sacc.index.size * 100 / total]\n",
    "        nr_gz_out = nr_gz_out + [gaze_out.index.size * 100 / total]\n",
    "        nr_sc_out = nr_sc_out + [sacc_out.index.size * 100 / total]\n",
    "        non_val = non_val + [outbig.index.size * 100 / total]\n",
    "        # santiy check that the numbers add up\n",
    "        total_nr = total_nr + [gaze.index.size * 100 / total + sacc.index.size * 100 / total + gaze_out.index.size * 100 / total + sacc_out.index.size * 100 \n",
    "                               / total + outbig.index.size * 100 / total]\n",
    "    # all all numbers to a df\n",
    "    stats[\"Gaze\"] = nr_gaze\n",
    "    stats[\"Sacc\"] = nr_sacc\n",
    "    stats[\"Out Gaze\"] = nr_gz_out\n",
    "    stats[\"Out Sacc\"] = nr_sc_out\n",
    "    stats[\"Invalid\"] = non_val\n",
    "    stats[\"Total\"] = total_nr\n",
    "    stats = pd.DataFrame(stats)\n",
    "    # display(stats) # enable this, when wanting to print the individual values\n",
    "    \n",
    "    # plot the resuls: one suplot per segmentation method\n",
    "    plt.subplot(1, 2, fe + 1)\n",
    "    # define the color pallet\n",
    "    pallet = {\n",
    "        \"Gaze\": gaze_color_1,\n",
    "        \"Sacc\": sacc_color_1,\n",
    "        \"Out Gaze\": gaze_color_2,\n",
    "        \"Out Sacc\": sacc_color_2,\n",
    "        \"Invalid\": colliders_color,\n",
    "    }\n",
    "    # plot the data as violinplot\n",
    "    sns.violinplot(\n",
    "        data=stats[\n",
    "            [\"Gaze\", \"Sacc\",\"Out Gaze\", \"Out Sacc\", \"Invalid\"]\n",
    "        ],\n",
    "        palette=pallet,\n",
    "        orient=\"v\",\n",
    "        inner=\"box\",\n",
    "        alpha=0.2,\n",
    "    )\n",
    "    # plot the individual datapoints on top of the violinplot\n",
    "    sns.swarmplot(\n",
    "        data=stats[\n",
    "            [\"Gaze\", \"Sacc\",\"Out Gaze\", \"Out Sacc\", \"Invalid\"]\n",
    "        ],\n",
    "        color=\"black\",\n",
    "        marker=\"o\",\n",
    "        size=6,\n",
    "    )\n",
    "    \n",
    "    # add a y-axis label only for the left plot\n",
    "    if fe == 0:\n",
    "        ax[fe].set_ylabel(\"Distribution in %\", fontsize=labelsize, fontname=fname)\n",
    "    \n",
    "    # set axis ticks\n",
    "    for label in ax[fe].get_xticklabels(): # change tick font\n",
    "        label.set_fontproperties(fname)\n",
    "    for label in ax[fe].get_yticklabels():\n",
    "        label.set_fontproperties(fname)\n",
    "    ax[fe].xaxis.set_tick_params(labelsize=labelsize)  # change tick size\n",
    "    ax[fe].yaxis.set_tick_params(labelsize=ticksize)  # change tick size\n",
    "\n",
    "ax[0].set_title(\"A\", fontsize=numbersize, fontweight=\"bold\",loc=\"left\", x=-0.07, y=1.05, pad=-30, fontname=fname)\n",
    "ax[1].set_title(\"B\", fontsize=numbersize, fontweight=\"bold\",loc=\"left\", x=-0.07, y=1.05, pad=-30, fontname=fname)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e56237-633b-4280-a086-8a2cd388971c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Check if there is a statistical significnace between any of the plotted options.\n",
    "This is done for gazes, saccades, long events (outliers) and invalid data.\n",
    "Similar code as above, but this time we don't plot the results but do statistical tests.\n",
    "'''\n",
    "\n",
    "print(\"% of events and outliers\")\n",
    "print()\n",
    "\n",
    "ids = recordings.index.tolist()\n",
    "idd = ids[:]\n",
    "\n",
    "# do this for each segmentation algorithm\n",
    "for fe in range(2):\n",
    "    # lists to save the data from every subject\n",
    "    nr_gaze = []\n",
    "    nr_sacc = []\n",
    "    nr_gz_out = []\n",
    "    nr_sc_out = []\n",
    "    non_val = []\n",
    "    total_nr = []\n",
    "    nr_out = []\n",
    "    # create individual dfs + get the segment name\n",
    "    if fe == 0:\n",
    "        stats_10 = {}\n",
    "        condition = \"10 second intervals\"\n",
    "    else:\n",
    "        stats_dd = {}\n",
    "        condition = \"Data driven intervals\"\n",
    "    mean_std = {}\n",
    "    # loop through all subjects (once per segmentation method)\n",
    "    for uid in idd:\n",
    "        # load data\n",
    "        if fe == 0: # 10 sec\n",
    "            for_eye = pd.read_csv(\n",
    "                f\"{PATH_FOREYE}/correTS__10sec_{uid}.csv\", index_col=0\n",
    "            )\n",
    "        else: # data-driven\n",
    "            for_eye = pd.read_csv(\n",
    "                f\"{PATH_FOREYE}/correTS_mad_wobig_{uid}.csv\", index_col=0\n",
    "            )\n",
    "\n",
    "        # get the total duration\n",
    "        total = for_eye.index.size\n",
    "\n",
    "        # get the number of invalid datapoints\n",
    "        outbig = for_eye[for_eye[\"valid\"] == 0.0]\n",
    "        for_eye = for_eye[for_eye[\"valid\"] == 1.0]\n",
    "\n",
    "        # for all valid datapoints, separate the data between gaze and saccade\n",
    "        gaze = for_eye[~for_eye[\"isFix\"].isnull()]\n",
    "        sacc = for_eye[for_eye[\"isFix\"].isnull()]\n",
    "\n",
    "        # further, separate gazes and saccades between outliers and valid events\n",
    "        gaze_out = gaze[gaze[\"long_events\"].isnull()]\n",
    "        sacc_out = sacc[sacc[\"long_events\"].isnull()]\n",
    "        gaze = gaze[~gaze[\"long_events\"].isnull()]\n",
    "        sacc = sacc[~sacc[\"long_events\"].isnull()]\n",
    "\n",
    "        # now calculate the percentage for each category\n",
    "        nr_gaze = nr_gaze + [gaze.index.size * 100 / total]\n",
    "        nr_sacc = nr_sacc + [sacc.index.size * 100 / total]\n",
    "        nr_gz_out = nr_gz_out + [gaze_out.index.size * 100 / total]\n",
    "        nr_sc_out = nr_sc_out + [sacc_out.index.size * 100 / total]\n",
    "        nr_out = nr_out + [outbig.index.size * 100 / total + gaze_out.index.size * 100 / total + sacc_out.index.size * 100 / total]\n",
    "        non_val = non_val + [outbig.index.size * 100 / total]\n",
    "        # santiy check that the numbers add up\n",
    "        total_nr = total_nr + [gaze.index.size * 100 / total + sacc.index.size * 100 / total + gaze_out.index.size * 100 / total + sacc_out.index.size * 100 / total + outbig.index.size * 100 / total]\n",
    "\n",
    "    # now get a df for mean + std across all subjects:\n",
    "    mean_std['mean'] = {}\n",
    "    mean_std['std'] = {}\n",
    "    mean_std['mean']['nr_gaze'] = np.mean(nr_gaze)\n",
    "    mean_std['std']['nr_gaze'] = np.std(nr_gaze)\n",
    "    mean_std['mean']['nr_sacc'] = np.mean(nr_sacc)\n",
    "    mean_std['std']['nr_sacc'] = np.std(nr_sacc)\n",
    "    mean_std['mean']['nr_gz_out'] = np.mean(nr_gz_out)\n",
    "    mean_std['std']['nr_gz_out'] = np.std(nr_gz_out)\n",
    "    mean_std['mean']['nr_sc_out'] = np.mean(nr_sc_out)\n",
    "    mean_std['std']['nr_sc_out'] = np.std(nr_sc_out)\n",
    "    mean_std['mean']['nr_out'] = np.mean(nr_out)\n",
    "    mean_std['std']['nr_out'] = np.std(nr_out)\n",
    "    mean_std['mean']['non_val'] = np.mean(non_val)\n",
    "    mean_std['std']['non_val'] = np.std(non_val)\n",
    "    mean_std = pd.DataFrame(mean_std)\n",
    "\n",
    "    # display the results of median and IQR\n",
    "    print(f\"% events and outliers - {condition}\")\n",
    "    print()\n",
    "    # Gaze\n",
    "    print(f\"Median % Gaze: {np.nanmedian(nr_gaze)}\")\n",
    "    q75, q25 = np.nanpercentile(nr_gaze, [75, 25])\n",
    "    iqr = q75 - q25\n",
    "    print(f\"IQR % Gaze: {iqr} ({q25}-{q75})\")\n",
    "    # Sacc\n",
    "    print(f\"Median % Sacc: {np.nanmedian(nr_sacc)}\")\n",
    "    q75, q25 = np.nanpercentile(nr_sacc, [75, 25])\n",
    "    iqr = q75 - q25\n",
    "    print(f\"IQR % Sacc: {iqr} ({q25}-{q75})\")\n",
    "    # Gaze_out\n",
    "    print(f\"Median % Gaze_out: {np.nanmedian(nr_gz_out)}\")\n",
    "    q75, q25 = np.nanpercentile(nr_gz_out, [75, 25])\n",
    "    iqr = q75 - q25\n",
    "    print(f\"IQR % Gaze_out: {iqr} ({q25}-{q75})\")\n",
    "    # Sacc_out\n",
    "    print(f\"Median % Sacc_out: {np.nanmedian(nr_sc_out)}\")\n",
    "    q75, q25 = np.nanpercentile(nr_sc_out, [75, 25])\n",
    "    iqr = q75 - q25\n",
    "    print(f\"IQR % Sacc_out: {iqr} ({q25}-{q75})\")\n",
    "    print(f\"Median % Total Outliers: {np.nanmedian(nr_out)}\")\n",
    "    print()\n",
    "\n",
    "    # add the results to the individual dfs\n",
    "    if fe == 0:\n",
    "        stats_10[\"Gaze\"] = nr_gaze\n",
    "        stats_10[\"Sacc\"] = nr_sacc\n",
    "        stats_10[\"Out Gaze\"] = nr_gz_out\n",
    "        stats_10[\"Out Sacc\"] = nr_sc_out\n",
    "        stats_10[\"Invalid\"] = non_val\n",
    "        stats_10[\"Total\"] = total_nr\n",
    "        stats_10[\"total_out\"] = nr_out\n",
    "        stats_10 = pd.DataFrame(stats_10)\n",
    "    else:\n",
    "        stats_dd[\"Gaze\"] = nr_gaze\n",
    "        stats_dd[\"Sacc\"] = nr_sacc\n",
    "        stats_dd[\"Out Gaze\"] = nr_gz_out\n",
    "        stats_dd[\"Out Sacc\"] = nr_sc_out\n",
    "        stats_dd[\"Invalid\"] = non_val\n",
    "        stats_dd[\"Total\"] = total_nr\n",
    "        stats_dd[\"total_out\"] = nr_out\n",
    "        stats_dd = pd.DataFrame(stats_dd)\n",
    "\n",
    "# Invalid: display the results and IQR\n",
    "print(f\"Median % Invalid: {np.nanmedian(non_val)}\")\n",
    "# Interquartile range:\n",
    "q75, q25 = np.nanpercentile(non_val, [75, 25])\n",
    "iqr = q75 - q25\n",
    "print(f\"IQR % Invalid: {iqr} ({q25}-{q75})\")\n",
    "print()\n",
    "\n",
    "alpha = 0.05\n",
    "adjusted_alpha = alpha / 4  # Four tests were performed\n",
    "print(f\"Adjusted alpha: {adjusted_alpha:.4f}\")\n",
    "print()\n",
    "\n",
    "# Display a KS test between the two segmentation intervals\n",
    "for column in stats_dd:\n",
    "    if column not in ['Invalid', 'Total', 'total_out']:\n",
    "        statistic, pvalue = ks_2samp(stats_10[column], stats_dd[column])\n",
    "        # Print the p-values\n",
    "        if pvalue <= adjusted_alpha: # if significant \n",
    "            print(f\"Adjusted p-value {column}: {pvalue:.4f} - this test is significant after Bonferroni correction\")\n",
    "        else: # if non significant\n",
    "            print(f\"Adjusted p-value {column}: {pvalue:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d030ddd-cf67-4456-b734-4cf324fefafe",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Event Durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904e90e6-7002-4d2d-b236-42a35c62ff99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Plot the durations of gazes and saccades.\n",
    "Additionally, a KS test to see if there is a significant difference between both is clauclates.\n",
    "'''\n",
    "\n",
    "# plot the data without outliers across all subject\n",
    "ids = recordings.index.tolist()\n",
    "idd = ids[:]\n",
    "\n",
    "\n",
    "# prepare the plot\n",
    "sns.set(rc={\"figure.figsize\": (30,20)})\n",
    "sns.set_style(\n",
    "    \"white\"\n",
    ") \n",
    "f, (axis) = plt.subplots(1, 1, sharey=True,)\n",
    "\n",
    "# define:\n",
    "labelsize = 40 # text\n",
    "legendsize = 40 # ledgend\n",
    "ticksize = 30 # ticks\n",
    "numbersize = 60 # A, B etc.\n",
    "fname = \"Arial\" # font name\n",
    "plt.rcParams[\"font.family\"] = fname\n",
    "\n",
    "# lists used for the statistical tests\n",
    "gze = []\n",
    "sac = []\n",
    "\n",
    "# we want to plot all saccades first and then all gazes, so we loop through all subejcts twice:\n",
    "\n",
    "# saccades\n",
    "for uid in idd:\n",
    "    # load the data\n",
    "    for_eye = pd.read_csv(\n",
    "        f\"{PATH_FOREYE}/correTS_mad_wobig_{uid}.csv\", index_col=0\n",
    "    )\n",
    "    c = sacc_color_1 # sacc color\n",
    "    l = \"Average Saccade Durations\" # name for ledgend\n",
    "\n",
    "    # separate between gaze and saccade\n",
    "    sacc = for_eye[for_eye[\"events\"] == 1.0]\n",
    "    # exclude long events\n",
    "    sacc = sacc[~sacc[\"long_events\"].isnull()]\n",
    "    # add the median for statistics\n",
    "    sac.append(np.nanmedian(sacc[\"length\"]))\n",
    "    # plot the saccades\n",
    "    sns.kdeplot(\n",
    "        sacc[\"length\"],\n",
    "        color=c,\n",
    "        fill=False,\n",
    "        alpha=0.2,\n",
    "        clip=[0, 1],\n",
    "        linewidth=3.5,\n",
    "        label=l,\n",
    "    )  \n",
    "\n",
    "# gazes:\n",
    "for uid in idd:\n",
    "    # load data\n",
    "    for_eye = pd.read_csv(\n",
    "        f\"{PATH_FOREYE}/correTS_mad_wobig_{uid}.csv\", index_col=0\n",
    "    )\n",
    "    c = gaze_color_1 # gaze color\n",
    "    l = \"Average Gaze Durations\" # ledgend\n",
    "\n",
    "    # separate between gaze and saccade\n",
    "    gaze = for_eye[for_eye[\"events\"] == 2.0]\n",
    "    # exclude long events\n",
    "    gaze = gaze[~gaze[\"long_events\"].isnull()]\n",
    "    # add for statistics\n",
    "    gze.append(np.nanmedian(gaze[\"length\"]))\n",
    "    # plot gazes\n",
    "    sns.kdeplot(\n",
    "        gaze[\"length\"],\n",
    "        color=c,\n",
    "        fill=False,\n",
    "        alpha=0.5,\n",
    "        cut = 0,\n",
    "        clip=[0, 1],\n",
    "        linewidth=3.5,\n",
    "        label=l,\n",
    "    )\n",
    "\n",
    "# calculate and display the statistics\n",
    "print(\"data-driven interval\")\n",
    "# as they are not completely normally distributed, we will use median to get the average results:\n",
    "med_gaze = np.nanmedian(gze)\n",
    "med_sacc = np.nanmedian(sac)\n",
    "print(f\"Median gaze duration: {med_gaze}\")\n",
    "print(f\"Median sacc duration: {med_sacc}\")\n",
    "# Interquartile range:\n",
    "q75_g, q25_g = np.nanpercentile(gze, [75, 25])\n",
    "iqr_gaze = q75_g - q25_g\n",
    "q75_s, q25_s = np.nanpercentile(sac, [75, 25])\n",
    "iqr_sacc = q75_s - q25_s\n",
    "print(f\"IQR gaze duration: {iqr_gaze} ({q25_g}-{q75_g})\")\n",
    "print(f\"IQR sacc duration: {iqr_sacc} ({q25_s}-{q75_s})\")\n",
    "\n",
    "# Perform the KS test\n",
    "print()\n",
    "statistic, pvalue = ks_2samp(gze, sac)\n",
    "print(f\"KS statistic: {statistic:.4f}\")\n",
    "print(f\"P-value: {pvalue:.4f}\")\n",
    "alpha = 0.05\n",
    "print(f\"Alpha: {alpha:.4f}\")\n",
    "# Now also get the mean to compare to other studies:\n",
    "mean_gaze = np.nanmean(gze)\n",
    "mean_sacc = np.nanmean(sac)\n",
    "std_gaze = np.std(gze)\n",
    "std_sacc = np.std(sac)\n",
    "print(f\"Mean gaze duration: {mean_gaze}; std: {std_gaze}\")\n",
    "print(f\"Mean sacc duration: {mean_sacc}; std: {std_sacc}\")\n",
    "print()\n",
    "\n",
    "# back to the plot:\n",
    "# set legend \n",
    "handles, labels = axis.get_legend_handles_labels()\n",
    "\n",
    "leg = axis.legend([handles[0], handles[-1]],\n",
    "                [labels[0], labels[-1]],\n",
    "                loc=\"upper right\", fontsize=legendsize)#\n",
    "for lh in leg.legendHandles:\n",
    "    lh.set_alpha(1)\n",
    "\n",
    "# set axis labels and ticks\n",
    "axis.set_xlabel(\"Duration (sec)\", fontsize=labelsize, fontname=fname)\n",
    "axis.set_ylabel(\"Density of Durations\", fontsize=labelsize, fontname=fname)\n",
    "for label in axis.get_xticklabels(): # change tick font\n",
    "    label.set_fontproperties(fname)\n",
    "for label in axis.get_yticklabels():\n",
    "    label.set_fontproperties(fname)\n",
    "axis.yaxis.set_tick_params(labelsize=ticksize)  # change tick size\n",
    "axis.xaxis.set_tick_params(labelsize=ticksize)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34898d64-14de-4fb5-aa9e-74dab7c0d460",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Velocity distribution in relation to gaze onset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac08d12c-8913-4e6e-8f01-425fb2d92141",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Create a plot for the velocity distributions:\n",
    "1. show the distribution of one subject\n",
    "2. show the average distribution\n",
    "3. plot the peak velocity\n",
    "'''\n",
    "ids = recordings.index.tolist()\n",
    "idd = ids[:2]\n",
    "\n",
    "# set up the farames before and after gaze onset\n",
    "start_fr = 20  # how many frames before gaze onset\n",
    "end_fr = 35  # how many frames to include after gaze onset\n",
    "\n",
    "data = {} # save data\n",
    "trials_all = []\n",
    "start_fr_peak = 10  # how many frames before gaze onset\n",
    "\n",
    "# set up figure\n",
    "sns.set(rc={\"figure.figsize\": (30, 30)})\n",
    "sns.set_style(\"white\") \n",
    "f, (ax) = plt.subplots(3,1, constrained_layout=True)\n",
    "\n",
    "# define:\n",
    "labelsize = 40 # text\n",
    "legendsize = 40 # ledgend\n",
    "ticksize = 30 # ticks\n",
    "numbersize = 60 # A, B etc.\n",
    "fname = \"Arial\" # font name\n",
    "plt.rcParams[\"font.family\"] = fname\n",
    "\n",
    "# loop through all subjects\n",
    "for i, uid in enumerate(idd):\n",
    "    # load data\n",
    "    for_eye = pd.read_csv(\n",
    "        f\"{PATH_FOREYE}/correTS_mad_wobig_{uid}.csv\", index_col=0\n",
    "    )\n",
    "\n",
    "    ####### Velocity over trials #######\n",
    "    # we only want to show the individual subject for the first one\n",
    "    if i == 0:\n",
    "        # we create a new df, as we will round down the velocities to 200\n",
    "        # this is done for this plot only\n",
    "        for_eye_new = for_eye \n",
    "        # replace all velocities over 200 with 200\n",
    "        combined_vel = for_eye[\"combined_vel\"].tolist()\n",
    "        c_v = [200 if cv > 200 else cv for cv in combined_vel]\n",
    "        for_eye_new[\"combined_vel\"] = c_v # add velocities back to new df\n",
    "        # get gazes\n",
    "        gaze = for_eye_new[for_eye_new[\"events\"] == 2.0]\n",
    "        gaze = gaze[~gaze[\"long_events\"].isnull()]\n",
    "        # get a subset of trials\n",
    "        gaze = gaze.iloc[50:250]\n",
    "        # now go through the trials\n",
    "        trials = {}\n",
    "        for g, gz in enumerate(gaze.index.tolist()):\n",
    "            # get the data segment for each trial (using the previously defined number of gazes)\n",
    "            cur = for_eye.iloc[gz - start_fr : gz + end_fr]\n",
    "            # add them to a trials df\n",
    "            trials[g] = cur[\"combined_vel\"].tolist()\n",
    "        \n",
    "        trials = pd.DataFrame(trials).transpose()\n",
    "        trials = trials.to_numpy()\n",
    "        # take out all nan samples and replace them with 0 (for plotting)\n",
    "        trials[np.isnan(trials)] = 0\n",
    "        # plot the results\n",
    "        sns.heatmap(trials, cmap=\"YlGnBu\", xticklabels=10, yticklabels=50, ax=ax[0])  \n",
    "        # set a red line at gaze onset\n",
    "        ax[0].axvline(x=start_fr, linewidth=3, color=sacc_color_1)\n",
    "        # set axis labels + font\n",
    "        ax[0].set_xlabel(\"Time (ms)\", fontsize=labelsize, fontname=fname)\n",
    "        ax[0].set_ylabel(\"Trials\", fontsize=labelsize, fontname=fname)\n",
    "        # set axis ticks + font\n",
    "        for label in ax[0].get_xticklabels(): # change tick font\n",
    "            label.set_fontproperties(fname)\n",
    "        for label in ax[0].get_yticklabels():\n",
    "            label.set_fontproperties(fname)\n",
    "        ax[0].yaxis.set_tick_params(labelsize=ticksize)  # change tick size\n",
    "        ax[0].xaxis.set_tick_params(labelsize=ticksize)\n",
    "        # set color bar\n",
    "        cbar = ax[0].collections[0].colorbar\n",
    "        cbar.ax.tick_params(labelsize=ticksize)\n",
    "        cbar.set_label(\"Angular Velocity\", fontsize=labelsize, fontname=fname)\n",
    "        # set x tick labels\n",
    "        ax[0].set_xticklabels([-220,-110,0,110,220,330],)\n",
    "        \n",
    "        # adjust the frames after gaze onset, so that the red lines in the next plots are aligned\n",
    "        end_fr = end_fr + 3\n",
    "\n",
    "    ####### Velocity over subjects #######\n",
    "    # get gazes\n",
    "    gaze = for_eye[for_eye[\"events\"] == 2.0]\n",
    "    gaze = gaze[~gaze[\"long_events\"].isnull()]\n",
    "    # now go through the trials\n",
    "    trials = {}\n",
    "    for g, gz in enumerate(gaze.index.tolist()):\n",
    "        # only use trials that have datapoints for all frames needed\n",
    "        if (gz - start_fr) > 0 and (gz + end_fr) < len(for_eye):\n",
    "            # get the current segment\n",
    "            cur = for_eye.iloc[gz - start_fr : gz + end_fr]\n",
    "            # add it to trial df\n",
    "            trials[g] = cur[\"combined_vel\"].tolist()\n",
    "    trials = pd.DataFrame(trials).transpose()\n",
    "    # add the median for this subjects to data (will be used to plot median across subjects)\n",
    "    data[uid[:5]] = trials.median(skipna=True)\n",
    "    # plot this result\n",
    "    ax[1].plot(list(range(-start_fr,end_fr)), data[uid[:5]], color=gaze_color_1, \n",
    "                linestyle='solid',linewidth=1.5, alpha=0.4, label=\"Average Velocity per Participant\")\n",
    "\n",
    "    ####### Peak Velocities #######\n",
    "    # get gazes\n",
    "    gaze = for_eye[for_eye[\"events\"] == 2.0]\n",
    "    gaze = gaze[~gaze[\"long_events\"].isnull()]\n",
    "    trials = []\n",
    "    # loop though all gazes\n",
    "    for g, gz in enumerate(gaze.index.tolist()):\n",
    "        # only use trials that have datapoints for all frames needed\n",
    "        if gz - start_fr_peak > 0 and gz + 3 < len(gaze.index.tolist()):\n",
    "            # get data segment\n",
    "            cur = for_eye.iloc[gz - start_fr_peak : gz + 3]\n",
    "            # get the index of the peak velocity\n",
    "            trials.append(\n",
    "                cur[\"combined_vel\"]\n",
    "                .tolist()\n",
    "                .index(np.nanmax(cur[\"combined_vel\"].tolist()))\n",
    "            )\n",
    "            # get the index of the peak velocity but save it for all subjects\n",
    "            trials_all.append(\n",
    "                cur[\"combined_vel\"]\n",
    "                .tolist()\n",
    "                .index(np.nanmax(cur[\"combined_vel\"].tolist()))\n",
    "            )\n",
    "    # plot the peak vels for each subject\n",
    "    sns.kdeplot(\n",
    "        trials,\n",
    "        bw_adjust=0.5, #0.4,\n",
    "        color=gaze_color_1,\n",
    "        alpha=0.06,\n",
    "        fill=True,\n",
    "        ax = ax[2]\n",
    "    )\n",
    "\n",
    "    \n",
    "####### Velocity over subjects #######\n",
    "data = pd.DataFrame(data).transpose()\n",
    "# get median across subjects\n",
    "finished_data = data.median(skipna=True)\n",
    "# plot the resul\n",
    "ax[1].plot(list(range(-start_fr,end_fr)), finished_data, color='k', \n",
    "    linestyle='solid', marker='o',linewidth=4, label=\"Average Velocity across Participants\")\n",
    "# legend:\n",
    "handles, labels = ax[1].get_legend_handles_labels()\n",
    "line2d_obj = Line2D([0], [0], linewidth=3, linestyle='solid', alpha = 1.0)\n",
    "handles[-2] = line2d_obj\n",
    "ax[1].legend(handles[-2:],labels[-2:],loc=\"upper right\", fontsize=legendsize)\n",
    "# plot a red line at gaze onset\n",
    "ax[1].axvline(x=0, linewidth=3, color=sacc_color_1)\n",
    "# axis labels\n",
    "ax[1].set_xlabel(\"Time (ms)\", fontsize=labelsize, fontname=fname)\n",
    "ax[1].set_ylabel(\"Average Velocity\", fontsize=labelsize, fontname=fname)\n",
    "# ticks \n",
    "for label in ax[1].get_xticklabels(): # change tick font\n",
    "    label.set_fontproperties(fname)\n",
    "for label in ax[1].get_yticklabels():\n",
    "    label.set_fontproperties(fname)\n",
    "ax[1].yaxis.set_tick_params(labelsize = ticksize) # change tick size\n",
    "ax[1].xaxis.set_tick_params(labelsize = ticksize)\n",
    "ax[1].set_xticklabels([-330,-220,-110,0,110,220,330],)\n",
    "\n",
    "####### Peak Velocities #######\n",
    "# plot the peak velocities across subjects\n",
    "sns.kdeplot(\n",
    "    trials_all,\n",
    "    bw_adjust=0.5,\n",
    "    color=\"k\",\n",
    "    linewidth = 3,\n",
    "    ax = ax[2]\n",
    ")\n",
    "# plot a red line a gaze onset\n",
    "ax[2].axvline(x=start_fr_peak, linewidth=3, color=sacc_color_1)\n",
    "# axis labels\n",
    "ax[2].set_xlabel(\"Time (ms)\", fontsize=labelsize, fontname=fname)\n",
    "ax[2].set_ylabel(\"Density of Peak Velocities\", fontsize=labelsize, fontname=fname)\n",
    "for label in ax[2].get_xticklabels(): # change tick font\n",
    "    label.set_fontproperties(fname)\n",
    "for label in ax[2].get_yticklabels():\n",
    "    label.set_fontproperties(fname)\n",
    "# ticks\n",
    "ax[2].yaxis.set_tick_params(labelsize=ticksize)  # change tick size\n",
    "ax[2].xaxis.set_tick_params(labelsize=ticksize)\n",
    "ax[2].set_xticks(list(np.arange(-3, 15, 1)),)\n",
    "ax[2].set_xticklabels(list(np.arange(-143, 55, 11)),)\n",
    "xticks = ax[2].xaxis.get_major_ticks()\n",
    "ticks = [0,1,2,4,5,6,7,9,10,11,12,14,15,16,17]\n",
    "for x in ticks:\n",
    "    xticks[x].label1.set_visible(False)  # Hide the 4th x-tick\n",
    "ax[2].locator_params(nbins=5, axis='y')\n",
    "\n",
    "ax[0].set_title(\"A\", fontsize=numbersize, fontweight=\"bold\",loc=\"left\", x=-0.08, y=1.05, pad=-30, fontname=fname)  \n",
    "ax[1].set_title(\"B\", fontsize=numbersize, fontweight=\"bold\",loc=\"left\", x=-0.08, y=1.05, pad=-30, fontname=fname) \n",
    "ax[2].set_title(\"C\", fontsize=numbersize, fontweight=\"bold\",loc=\"left\", x=-0.08, y=1.05, pad=-30, fontname=fname)  \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b32c85-12c7-4a13-aa5a-72c6ecc8617d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Dispersion distribution in relation to gaze onset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948f696c-b8d7-4833-a65f-48fc4bc8f12b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# display the dispersion distribution\n",
    "ids = recordings.index.tolist()\n",
    "idd = ids[:]\n",
    "\n",
    "start_fr = 20  # how many frames before gaze onset\n",
    "end_fr = 38  # how many frames to include after gaze onset\n",
    "\n",
    "# save the data\n",
    "data_driven = {}\n",
    "\n",
    "\n",
    "# plot it:\n",
    "sns.set(rc={\"figure.figsize\": (30, 7)})\n",
    "sns.set_style(\n",
    "    \"white\"\n",
    ")\n",
    "f, (ax) = plt.subplots(1)\n",
    "\n",
    "# define\n",
    "labelsize = 40 # text\n",
    "legendsize = 40 # ledgend\n",
    "ticksize = 30 # ticks\n",
    "numbersize = 60 # A, B etc.\n",
    "fname = \"Arial\" # font name\n",
    "plt.rcParams[\"font.family\"] = fname\n",
    "\n",
    "data = {}  # save data\n",
    "# we go through each subject:\n",
    "for i, uid in enumerate(idd):\n",
    "    # load data\n",
    "    for_eye = pd.read_csv(\n",
    "        f\"{PATH_FOREYE}/correTS_mad_wobig_{uid}.csv\", index_col=0\n",
    "    )\n",
    "\n",
    "    # get distances between consecutive datapoints\n",
    "    distances = np.sqrt(np.square(for_eye['xhpoo'].diff()) + np.square(for_eye['yhpoo'].diff()) + np.square(for_eye['zhpoo'].diff()))\n",
    "    for_eye[\"distance_hpoo\"] = distances\n",
    "\n",
    "    # get gazes\n",
    "    gaze = for_eye[for_eye[\"events\"] == 2.0]\n",
    "    # get rid of long gaze events\n",
    "    gaze = gaze[~gaze[\"long_events\"].isnull()]\n",
    "\n",
    "    # now go through the trials\n",
    "    trials = {}\n",
    "    for g, gz in enumerate(gaze.index.tolist()):\n",
    "        # only use trials that have datapoints for all frames needed\n",
    "        if (gz - start_fr) > 0 and (gz + end_fr) < len(for_eye):\n",
    "            # det the corresponding datasegment\n",
    "            cur = for_eye.iloc[gz - start_fr : gz + end_fr]\n",
    "            # add it to df\n",
    "            trials[g] = cur[\"distance_hpoo\"].tolist()\n",
    "\n",
    "    trials = pd.DataFrame(trials).transpose()\n",
    "    # add the median for this subjects to data\n",
    "    data[uid[:5]] = trials.median(skipna=True)\n",
    "    # plot the dispersion for each subject\n",
    "    ax.plot(\n",
    "        list(range(-start_fr, end_fr)),\n",
    "        data[uid[:5]],\n",
    "        color=gaze_color_1,\n",
    "        linestyle=\"solid\",\n",
    "        linewidth=1,\n",
    "        alpha=0.4,\n",
    "        label=\"Average Dispersion per Participant\"\n",
    "    )\n",
    "\n",
    "# create df\n",
    "data = pd.DataFrame(data).transpose()\n",
    "# get median across subjects\n",
    "finished_data = data.median(skipna=True)\n",
    "# plot the data across subjects\n",
    "ax.plot(\n",
    "    list(range(-start_fr, end_fr)),\n",
    "    finished_data,\n",
    "    color=\"k\",\n",
    "    linestyle=\"solid\",\n",
    "    marker=\"o\",\n",
    "    linewidth=4,\n",
    "    label=\"Average Dispersion across Participants\"\n",
    ")\n",
    "\n",
    "# legend:\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "line2d_obj = Line2D([0], [0], linewidth=3, linestyle='solid', alpha = 1.0)\n",
    "handles[-2] = line2d_obj\n",
    "ax.legend(handles[-2:],labels[-2:],loc=\"upper right\", fontsize=legendsize)\n",
    "# plot a red line at gaze onset\n",
    "ax.axvline(x=0, linewidth=3, color=sacc_color_1)\n",
    "# axis labels\n",
    "ax.set_xlabel(\"Time (ms)\", fontsize=labelsize, fontname=fname)\n",
    "ax.set_ylabel(\"Change in Dispersion\", fontsize=labelsize, fontname=fname)\n",
    "for label in ax.get_xticklabels(): # change tick font\n",
    "    label.set_fontproperties(fname)\n",
    "for label in ax.get_yticklabels():\n",
    "    label.set_fontproperties(fname)\n",
    "# ticks\n",
    "ax.yaxis.set_tick_params(labelsize=ticksize)  # change tick size\n",
    "ax.xaxis.set_tick_params(labelsize=ticksize)\n",
    "ax.set_xticklabels([-330,-220,-110,0,110,220,330],)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15644781-89fc-4995-8748-5ede335ad621",
   "metadata": {
    "tags": []
   },
   "source": [
    "# EEG results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01741e7f-dc0f-4eb9-9871-c6e1b6fc8332",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## ERP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11347c9-209f-4156-947f-5eb801a78dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Compute Number of trials rejected and the number of trials going into the average ERPs\n",
    "data calculated in figures_ET_EEG_paper.m\n",
    "'''\n",
    "\n",
    "ids = recordings.index.tolist()\n",
    "idd = ids[:]\n",
    "\n",
    "mat = scipy.io.loadmat(f\"{PATH_EEG}/nr_trials_erp.mat\")\n",
    "mat = mat[\"nr_events\"]\n",
    "mat = pd.DataFrame(mat)\n",
    "\n",
    "\n",
    "print(f\"Median Amount of Trials for one fERP: {np.nanmedian(mat[0])}\")\n",
    "# Interquartile range:\n",
    "q75, q25 = np.nanpercentile(mat[0].tolist(), [75, 25])\n",
    "iqr_interp = q75 - q25\n",
    "print(f\"IQR gaze DD: {iqr_interp} ({q25}-{q75})\")\n",
    "# substract original nr of trials and those left\n",
    "\n",
    "\n",
    "tr = []\n",
    "for nr, uid in enumerate(idd):\n",
    "    trigger_file = pd.read_csv(f\"{PATH_TRG}/TriggerFile_newTSdd_{uid}.csv\", index_col=0)\n",
    "    tr = tr + [len(trigger_file) - mat.iloc[nr]]\n",
    "\n",
    "\n",
    "print(f\"Median Amount of Trials rejected: {np.nanmedian(tr)}\")\n",
    "# Interquartile range:\n",
    "q75, q25 = np.nanpercentile(tr, [75, 25])\n",
    "iqr_interp = q75 - q25\n",
    "print(f\"IQR: {iqr_interp} ({q25}-{q75})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98985c6-a168-455d-a815-269121ef2ad6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Plot ERPs:\n",
    "1. across subjects\n",
    "2. & 3. topoplots\n",
    "'''\n",
    "# set up figure\n",
    "# rc used to move the axins labels into the middle of the plot\n",
    "rc = {\"xtick.direction\" : \"inout\", \"ytick.direction\" : \"inout\",\n",
    "      \"xtick.major.size\" : 30, \"ytick.major.size\" : 30,\n",
    "      \"xtick.major.width\" : 2, \"ytick.major.width\" : 2,\n",
    "     \"figure.figsize\": (30, 32)}\n",
    "with plt.rc_context(rc):\n",
    "    plt.figure(constrained_layout=True)\n",
    "\n",
    "    # define\n",
    "    labelsize = 40 # text\n",
    "    legendsize = 40 # ledgend\n",
    "    ticksize = 30 # ticks\n",
    "    numbersize = 60 # A, B etc.\n",
    "    fname = \"Arial\" # font name\n",
    "    plt.rcParams[\"font.family\"] = fname\n",
    "    # set up grid\n",
    "    ax1 = plt.subplot2grid(shape=(5, 9), loc=(0, 0), rowspan=2, colspan=9)\n",
    "    ax2 = plt.subplot2grid(shape=(5, 9), loc=(2, 2), rowspan=2, colspan=4)\n",
    "    ax31 = plt.subplot2grid(shape=(5, 9), loc=(4, 0), rowspan=1, colspan=2)\n",
    "    ax32 = plt.subplot2grid(shape=(5, 9), loc=(4, 2), rowspan=1, colspan=2)\n",
    "    ax33 = plt.subplot2grid(shape=(5, 9), loc=(4, 4), rowspan=1, colspan=2)\n",
    "    ax34 = plt.subplot2grid(shape=(5, 9), loc=(4, 6), rowspan=1, colspan=2)\n",
    "    ax35 = plt.subplot2grid(shape=(5, 9), loc=(4, 8), rowspan=1, colspan=1)\n",
    "\n",
    "    ####### Average ERPs #######\n",
    "    # load the appropriate file: created with Matlab\n",
    "    mat = scipy.io.loadmat(f\"{PATH_EEG}/avg_erps.mat\")\n",
    "    times = mat[\"times\"].tolist()[0] # get time\n",
    "    mat = mat[\"avg_erps_no\"] # get average erps\n",
    "    mat = pd.DataFrame(mat)\n",
    "    # plot each subject ERP\n",
    "    for i in range(len(mat.index[:])):\n",
    "        # very first subject, is the sample one, plot it in red\n",
    "        if i == 0:\n",
    "            ax1.plot(times,mat.iloc[i].values.tolist(),color=sacc_color_1,alpha=0.5,label=\"Individual ERP (sample)\")\n",
    "        # first one, save the label for the ledgend\n",
    "        elif i ==1:\n",
    "            ax1.plot(times,mat.iloc[i].values.tolist(),color=gaze_color_1,alpha=0.2,label=\"Individual ERPs\")\n",
    "        # for the rest, don't save the labels\n",
    "        else:\n",
    "            ax1.plot(times,mat.iloc[i].values.tolist(),color=gaze_color_1,alpha=0.2,label=\"_Hidden label\")\n",
    "    # plot the average ERP\n",
    "    ax1.plot(times,mat.mean().tolist(),color=\"k\",linewidth=4,label=\"Average ERP\")\n",
    "    \n",
    "    # legend:\n",
    "    handles, labels = ax1.get_legend_handles_labels()\n",
    "    # make sure to only append three labels\n",
    "    new_handlers, new_labels = [], []\n",
    "    for h,l in zip(handles, labels):\n",
    "        if l in ['Individual ERP (sample)','Individual ERPs',\"Average ERP\"]:\n",
    "            new_handlers.append(h)\n",
    "            new_labels.append(l)\n",
    "    # change the legend item alpha to 1.0\n",
    "    line2d_obj1 = Line2D([0], [0], linewidth=3, linestyle='solid', alpha = 1.0, color = sacc_color_1)\n",
    "    line2d_obj2 = Line2D([0], [0], linewidth=3, linestyle='solid', alpha = 1.0, color = gaze_color_1)\n",
    "    new_handlers[-3] = line2d_obj1\n",
    "    new_handlers[-2] = line2d_obj2\n",
    "    legend = ax1.legend(new_handlers,new_labels,loc=\"upper right\", fontsize=legendsize, frameon=False)\n",
    "    \n",
    "    # axis labels\n",
    "    ax1.set_xlabel(\"ms\", fontsize=labelsize, fontname=fname)\n",
    "    ax1.xaxis.set_label_coords(0.985,0.376)\n",
    "    ax1.set_ylabel(u'$\\it{\\u03bc}$' + 'V', fontsize=labelsize, fontname=fname, loc='bottom', rotation = 0)\n",
    "    ax1.yaxis.set_label_coords(0.315,-0.005)\n",
    "    ax1.text(-227,-0.1,\"Oz\", fontsize=labelsize)\n",
    "    \n",
    "    # ticks\n",
    "    x = [-200,-100,100,200,300,400,500]\n",
    "    ax1.set_xticks(x)\n",
    "    y = [-2,-1,1,2,3]\n",
    "    ax1.set_yticks(y)\n",
    "    for label in ax1.get_xticklabels(): # change tick font\n",
    "        label.set_fontproperties(fname)\n",
    "    for label in ax1.get_yticklabels():\n",
    "        label.set_fontproperties(fname)\n",
    "    ax1.yaxis.set_tick_params(labelsize=ticksize)  # change tick size\n",
    "    ax1.xaxis.set_tick_params(labelsize=ticksize)\n",
    "    # text: A\n",
    "    ax1.set_title(\"A\", fontsize=50, fontweight=\"bold\",loc=\"left\", x=-0.07, y=1.05, pad=-30, fontname=fname) \n",
    "\n",
    "    # adjust spines\n",
    "    ax1.spines[['top','right']].set_visible(False)\n",
    "    ax1.spines[['bottom','left']].set_linewidth(2)\n",
    "    ax1.spines[['bottom','left']].set_position(('data', 0))\n",
    "    ax1.spines[['bottom','left']].set_clip_on(True)\n",
    "    ax1.spines[['left']].set_bounds([- 2,3])\n",
    "    ax1.spines[['bottom']].set_bounds([- 200,500])\n",
    "\n",
    "    ax1.xaxis.set_ticks_position('bottom')\n",
    "    ax1.yaxis.set_ticks_position('left')\n",
    "\n",
    "                                 \n",
    "    ####### Topoplot ######\n",
    "    # load the image (created with Matlab)\n",
    "    img = plt.imread(f\"{PATH_EEG}/Topoplot_ERPs.png\")\n",
    "    ax2.imshow(img)\n",
    "    ax2.axis('off')\n",
    "    ax2.set_title(\"B\", fontsize=50, fontweight=\"bold\",loc=\"left\", x=-0.07, y=1.05, pad=-30, fontname=fname) \n",
    "\n",
    "\n",
    "    ####### Topoplot 0.0 ######\n",
    "    # load the image (created with Matlab)\n",
    "    img = plt.imread(f\"{PATH_EEG}/Topoplot_0.png\")\n",
    "    ax31.imshow(img)\n",
    "    ax31.axis('off')\n",
    "    ax31.set_title(\"C\", fontsize=50, fontweight=\"bold\",loc=\"left\", x=-0.07, y=1.05, pad=-30, fontname=fname) \n",
    "    # add time interval description\n",
    "    ax31.text(0.5, -0.05, '0 : 20 ms',fontsize=27, horizontalalignment='center', verticalalignment='center', transform=ax31.transAxes, fontname=fname)\n",
    "\n",
    "    ####### Topoplot 0.08 ######\n",
    "    # load the image (created with Matlab)\n",
    "    img = plt.imread(f\"{PATH_EEG}/Topoplot_0.08.png\")\n",
    "    ax32.imshow(img)\n",
    "    ax32.axis('off')\n",
    "    # add time interval description\n",
    "    ax32.text(0.5, -0.05, '80 : 100 ms',fontsize=27, horizontalalignment='center', verticalalignment='center', transform=ax32.transAxes, fontname=fname)\n",
    "\n",
    "    ####### Topoplot 0.15 ######\n",
    "    # load the image (created with Matlab)\n",
    "    img = plt.imread(f\"{PATH_EEG}/Topoplot_0.15.png\")\n",
    "    ax33.imshow(img)\n",
    "    ax33.axis('off')\n",
    "    # add time interval description\n",
    "    ax33.text(0.5, -0.05, '150 : 170 ms',fontsize=27, horizontalalignment='center', verticalalignment='center', transform=ax33.transAxes, fontname=fname)\n",
    "\n",
    "    ####### Topoplot 0.28 ######\n",
    "    # load the image (created with Matlab)\n",
    "    img = plt.imread(f\"{PATH_EEG}/Topoplot_0.28.png\")\n",
    "    ax34.imshow(img)\n",
    "    ax34.axis('off')\n",
    "    # add time interval description\n",
    "    ax34.text(0.5, -0.05, '280 : 300 ms',fontsize=27, horizontalalignment='center', verticalalignment='center', transform=ax34.transAxes, fontname=fname)\n",
    "\n",
    "    ####### Colorbar ######\n",
    "    # load the image (created with Matlab)\n",
    "    img = plt.imread(f\"{PATH_EEG}/Topoplot_0_colorbar.png\")\n",
    "    ax35.imshow(img)\n",
    "    ax35.axis('off')\n",
    "    # add colorbar label\n",
    "    ax35.text(0.25, -0.05, u'\\u03bc' + 'V', fontsize=labelsize, horizontalalignment='center', verticalalignment='center', transform=ax35.transAxes, fontname=fname)\n",
    "\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d809b10-41f9-4500-9f6b-2e3f62777620",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## ERSPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b55590-4459-4252-ba55-7f58a71448d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labelsize = 35 #text\n",
    "\n",
    "# set up figure\n",
    "plt.figure(figsize=(30, 22), constrained_layout=True)\n",
    "sns.set_style(\n",
    "    \"white\"\n",
    ")\n",
    "# define:\n",
    "labelsize = 40 # text\n",
    "legendsize = 40 # ledgend\n",
    "ticksize = 30 # ticks\n",
    "numbersize = 60 # A, B etc.\n",
    "fname = \"Arial\" # font name\n",
    "plt.rcParams[\"font.family\"] = fname\n",
    "# define grid\n",
    "ax1 = plt.subplot2grid(shape=(4, 9), loc=(0, 0), rowspan=3, colspan=4)\n",
    "ax2 = plt.subplot2grid(shape=(4, 9), loc=(0, 5), rowspan=3, colspan=4)\n",
    "ax3 = plt.subplot2grid(shape=(4, 9), loc=(3, 0), rowspan=1, colspan=2)\n",
    "ax4 = plt.subplot2grid(shape=(4, 9), loc=(3, 2), rowspan=1, colspan=2)\n",
    "ax5 = plt.subplot2grid(shape=(4, 9), loc=(3, 4), rowspan=1, colspan=2)\n",
    "ax6 = plt.subplot2grid(shape=(4, 9), loc=(3, 6), rowspan=1, colspan=2)\n",
    "ax7 = plt.subplot2grid(shape=(4, 9), loc=(3, 8), rowspan=1, colspan=1)\n",
    "\n",
    "\n",
    "####### ERSP single subject ######\n",
    "# load image (created with Matlab)\n",
    "img = plt.imread(f\"{PATH_EEG}/NEW_ERSP_at_Oz_single_Subject.png\")\n",
    "ax1.imshow(img)\n",
    "ax1.set_yticklabels([])\n",
    "ax1.set_xticklabels([])\n",
    "ax1.spines['top'].set_visible(False)\n",
    "ax1.spines['right'].set_visible(False)\n",
    "ax1.spines['bottom'].set_visible(False)\n",
    "ax1.spines['left'].set_visible(False)\n",
    "ax1.set_title(\"A\", fontsize=numbersize, fontweight=\"bold\",loc=\"left\", x=-0.07, y=1.05, pad=-30, fontname=fname) \n",
    "# axis labels\n",
    "ax1.text(0.45, -0.03, 'time (s)',fontsize=labelsize, horizontalalignment='center', verticalalignment='center', transform=ax1.transAxes, fontname=fname)\n",
    "ax1.text(-0.03, 0.5, 'frequency (Hz)',fontsize=labelsize, horizontalalignment='center', verticalalignment='center', rotation = 90, transform=ax1.transAxes, fontname=fname)\n",
    "ax1.text(0.89, 0.04, 'Power',fontsize=labelsize-10, horizontalalignment='center', verticalalignment='center', transform=ax1.transAxes, fontname=fname)\n",
    "ax1.text(0.89, 0.005, '(db)',fontsize=labelsize-10, horizontalalignment='center', verticalalignment='center', transform=ax1.transAxes, fontname=fname)\n",
    "\n",
    "####### ERSP all subjects ######\n",
    "# load image (created with Matlab)\n",
    "img = plt.imread(f\"{PATH_EEG}/NEW_ERSP_at_Oz_all_Subject.png\")\n",
    "ax2.imshow(img)\n",
    "ax2.set_yticklabels([])\n",
    "ax2.set_xticklabels([])\n",
    "ax2.spines['top'].set_visible(False)\n",
    "ax2.spines['right'].set_visible(False)\n",
    "ax2.spines['bottom'].set_visible(False)\n",
    "ax2.spines['left'].set_visible(False)\n",
    "ax2.set_title(\"B\", fontsize=numbersize, fontweight=\"bold\",loc=\"left\", x=-0.07, y=1.05, pad=-30, fontname=fname) \n",
    "# axis labels\n",
    "ax2.text(0.45, -0.03, 'time (s)',fontsize=labelsize, horizontalalignment='center', verticalalignment='center', transform=ax2.transAxes, fontname=fname)\n",
    "ax2.text(-0.03, 0.5, 'frequency (Hz)',fontsize=labelsize, horizontalalignment='center', verticalalignment='center', rotation = 90, transform=ax2.transAxes, fontname=fname)\n",
    "ax2.text(0.89, 0.04, 'Power',fontsize=labelsize-10, horizontalalignment='center', verticalalignment='center', transform=ax2.transAxes, fontname=fname)\n",
    "ax2.text(0.89, 0.005, '(db)',fontsize=labelsize-10, horizontalalignment='center', verticalalignment='center', transform=ax2.transAxes, fontname=fname)\n",
    "\n",
    "####### Topo 1 single subject ######\n",
    "# load image (created with Matlab)\n",
    "img = plt.imread(f\"{PATH_EEG}/ERSP_topo_single_Subject_0-0.15s.jpg\")\n",
    "ax3.imshow(img)\n",
    "ax3.set_yticklabels([])\n",
    "ax3.set_xticklabels([])\n",
    "ax3.spines['top'].set_visible(False)\n",
    "ax3.spines['right'].set_visible(False)\n",
    "ax3.spines['bottom'].set_visible(False)\n",
    "ax3.spines['left'].set_visible(False)\n",
    "ax3.set_title(\"C\", fontsize=numbersize, fontweight=\"bold\",loc=\"left\", x=-0.07, y=1.2, pad=-30, fontname=fname) \n",
    "# axis labels\n",
    "ax3.text(0.15, -0.03, 'Freq = [4 15]',fontsize=labelsize-10, horizontalalignment='center', verticalalignment='center', transform=ax3.transAxes, fontname=fname)\n",
    "ax3.text(0.5, 1.05, '0 ms - 150 ms',fontsize=labelsize, horizontalalignment='center', verticalalignment='center', transform=ax3.transAxes, fontname=fname)\n",
    "\n",
    "####### Topo 2 single subject ######\n",
    "# load image (created with Matlab)\n",
    "img = plt.imread(f\"{PATH_EEG}/ERSP_topo_single_Subject_0.16-0.3s.jpg\")\n",
    "ax4.imshow(img)\n",
    "ax4.set_yticklabels([])\n",
    "ax4.set_xticklabels([])\n",
    "ax4.spines['top'].set_visible(False)\n",
    "ax4.spines['right'].set_visible(False)\n",
    "ax4.spines['bottom'].set_visible(False)\n",
    "ax4.spines['left'].set_visible(False)\n",
    "ax4.set_title(\"D\", fontsize=numbersize, fontweight=\"bold\",loc=\"left\", x=-0.07, y=1.2, pad=-30, fontname=fname) \n",
    "# axis labels\n",
    "ax4.text(0.15, -0.03, 'Freq = [4 15]',fontsize=labelsize-10, horizontalalignment='center', verticalalignment='center', transform=ax4.transAxes, fontname=fname)\n",
    "ax4.text(0.5, 1.05, '160 ms - 300 ms',fontsize=labelsize, horizontalalignment='center', verticalalignment='center', transform=ax4.transAxes, fontname=fname)\n",
    "\n",
    "####### Topo 1 all subjects ######\n",
    "# load image (created with Matlab)\n",
    "img = plt.imread(f\"{PATH_EEG}/ERSP_topo_all_Subject_0-0.15s.jpg\")\n",
    "ax5.imshow(img)\n",
    "ax5.set_yticklabels([])\n",
    "ax5.set_xticklabels([])\n",
    "ax5.spines['top'].set_visible(False)\n",
    "ax5.spines['right'].set_visible(False)\n",
    "ax5.spines['bottom'].set_visible(False)\n",
    "ax5.spines['left'].set_visible(False)\n",
    "ax5.set_title(\"E\", fontsize=numbersize, fontweight=\"bold\",loc=\"left\", x=-0.07, y=1.2, pad=-30, fontname=fname) \n",
    "# axis labels\n",
    "ax5.text(0.15, -0.03, 'Freq = [4 15]',fontsize=labelsize-10, horizontalalignment='center', verticalalignment='center', transform=ax5.transAxes, fontname=fname)\n",
    "ax5.text(0.5, 1.05, '0 ms - 150 ms',fontsize=labelsize, horizontalalignment='center', verticalalignment='center', transform=ax5.transAxes, fontname=fname)\n",
    "\n",
    "####### Topo 2 all subjects ######\n",
    "# load image (created with Matlab)\n",
    "img = plt.imread(f\"{PATH_EEG}/ERSP_topo_all_Subject_0.16-0.3s.jpg\")\n",
    "ax6.imshow(img)\n",
    "ax6.set_yticklabels([])\n",
    "ax6.set_xticklabels([])\n",
    "ax6.spines['top'].set_visible(False)\n",
    "ax6.spines['right'].set_visible(False)\n",
    "ax6.spines['bottom'].set_visible(False)\n",
    "ax6.spines['left'].set_visible(False)\n",
    "ax6.set_title(\"F\", fontsize=numbersize, fontweight=\"bold\",loc=\"left\", x=-0.07, y=1.2, pad=-30, fontname=fname) \n",
    "# axis labels\n",
    "ax6.text(0.15, -0.03, 'Freq = [4 15]',fontsize=labelsize-10, horizontalalignment='center', verticalalignment='center', transform=ax6.transAxes, fontname=fname)\n",
    "ax6.text(0.5, 1.05, '160 ms - 300 ms',fontsize=labelsize, horizontalalignment='center', verticalalignment='center', transform=ax6.transAxes, fontname=fname)\n",
    "\n",
    "####### Colorbar single subject ######\n",
    "# load image (created with Matlab)\n",
    "img = plt.imread(f\"{PATH_EEG}/NEW_Topoplot_all_Subject_colorbar.png\")\n",
    "ax7.imshow(img)\n",
    "ax7.set_yticklabels([])\n",
    "ax7.set_xticklabels([])\n",
    "ax7.spines['top'].set_visible(False)\n",
    "ax7.spines['right'].set_visible(False)\n",
    "ax7.spines['bottom'].set_visible(False)\n",
    "ax7.spines['left'].set_visible(False)\n",
    "# axis labels\n",
    "ax7.text(0.2, -0.03, 'Power',fontsize=labelsize-10, horizontalalignment='center', verticalalignment='center', transform=ax7.transAxes, fontname=fname)\n",
    "ax7.text(0.2, -0.09, '(db)',fontsize=labelsize-10, horizontalalignment='center', verticalalignment='center', transform=ax7.transAxes, fontname=fname)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90a1f56-c659-49a6-8f83-117fac7b15f8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Correlation ERPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2fa8d2-e417-4d9c-b85a-4d7b3041b602",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the mean correlation for the no-shift condition\n",
    "ids = recordings.index.tolist()\n",
    "idd = ids[:]\n",
    "\n",
    "no_shift = []\n",
    "for i, uid in enumerate(idd):\n",
    "    # load data\n",
    "    cond = \"dd\"\n",
    "    #load the appropriate file\n",
    "    mat = scipy.io.loadmat(f\"{PATH_EEG}/correlation_shift_{cond}_{subj_to_inlcude[i]}.mat\")\n",
    "    # get the data out if the mat file\n",
    "    mat = mat[\"corr_coef\"]\n",
    "    mat = pd.DataFrame(mat).transpose()\n",
    "\n",
    "    no_shift = no_shift + [np.median(mat[mat[0] != 0][0].tolist())]\n",
    "\n",
    "display(np.mean(no_shift))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ae4640-5e83-4107-beda-89925e807e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and ANOVA to test if the shifts are significantly different\n",
    "\n",
    "ids = recordings.index.tolist()\n",
    "idd = ids[:]\n",
    "\n",
    "no_shift = []\n",
    "pos_shift = []\n",
    "neg_shift = []\n",
    "\n",
    "for i, uid in enumerate(idd):\n",
    "    # load data\n",
    "    cond = \"dd\"\n",
    "    #load the appropriate file\n",
    "    mat = scipy.io.loadmat(f\"{PATH_EEG}/correlation_shift_{cond}_{subj_to_inlcude[i]}.mat\")\n",
    "    # get the data out if the mat file\n",
    "    mat = mat[\"corr_coef\"]\n",
    "    mat = pd.DataFrame(mat).transpose()\n",
    "\n",
    "    # save the median correlation for each shift condition\n",
    "    no_shift = no_shift + [np.median(mat[mat[0] != 0][0].tolist())]\n",
    "    pos_shift = pos_shift + [np.median(mat[mat[1] != 0][1].tolist())]\n",
    "    neg_shift = neg_shift + [np.median(mat[mat[2] != 0][2].tolist())]\n",
    "\n",
    "# create a df\n",
    "corr_long = {}\n",
    "corr_long['subject'] = [int(li) for li in np.linspace(0,18,19)] * 3 # subject nr\n",
    "corr_long['shift'] = ['no_shift'] * len(no_shift) + ['pos_shift'] * len(pos_shift) + ['neg_shift'] * len(neg_shift)\n",
    "corr_long['corr_coef'] = no_shift + pos_shift + neg_shift\n",
    "corr_long = pd.DataFrame(corr_long)\n",
    "\n",
    "### Repeated measure ANOVA\n",
    "print(\"Repeated measure ANOVA\")\n",
    "print(AnovaRM(data=corr_long, depvar='corr_coef',\n",
    "              subject='subject', within=['shift']).fit())\n",
    "print()\n",
    "### Check Assumtions:\n",
    "# 1. Sphericity using the Mauchly test\n",
    "mauchly_result = pg.sphericity(corr_long, dv='corr_coef', subject='subject', \n",
    "                               within='shift')\n",
    "print(mauchly_result)\n",
    "print()\n",
    "\n",
    "\n",
    "### Compute pairwise comparisons with Fisher's LSD test\n",
    "stat,p1 = scipy.stats.ttest_rel(no_shift, pos_shift)\n",
    "stat,p2 = scipy.stats.ttest_rel(no_shift, neg_shift)\n",
    "stat,p3 = scipy.stats.ttest_rel(pos_shift, neg_shift)\n",
    "\n",
    "p_values = [p1,p2,p3]\n",
    "\n",
    "print([round(pv,3) for pv in p_values])\n",
    "print()\n",
    "print('corrected p-values')\n",
    "corrected_p_values = multipletests(p_values, alpha=0.05, method='bonferroni')[1]\n",
    "print(corrected_p_values)\n",
    "corrected_p_values = [round(pv, 3) for pv in corrected_p_values]\n",
    "# Print the corrected p-value4\n",
    "print(corrected_p_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ad61f2-c272-464a-8f61-9e3af245f5d2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Correlation ERSPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccb0725-2453-417d-803c-d530a4931313",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Finished Version --> use this (20.03.23)\n",
    "ids = recordings.index.tolist()\n",
    "idd = ids[:]\n",
    "\n",
    "no_shift = []\n",
    "\n",
    "for i, uid in enumerate(idd):\n",
    "    # load data\n",
    "    cond = \"dd\"\n",
    "    #load the appropriate file\n",
    "    mat = scipy.io.loadmat(f\"{PATH_EEG}/correlation_shift_ERSP_{cond}_{subj_to_inlcude[i]}.mat\")\n",
    "\n",
    "    # get the data out if the mat file\n",
    "    mat = mat[\"corr_coef\"]\n",
    "    mat = pd.DataFrame(mat).transpose()\n",
    "    # get the median correlation\n",
    "    no_shift = no_shift + [np.median(mat[mat[0] != 0][0].tolist())]\n",
    "\n",
    "# display the mean across subjects\n",
    "display(np.mean(no_shift))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59874977-f5fa-479a-893c-45ffbd76e031",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute and ANOVA to test if the shifts are significantly different\n",
    "\n",
    "ids = recordings.index.tolist()\n",
    "idd = ids[:]\n",
    "\n",
    "no_shift = []\n",
    "pos_shift = []\n",
    "neg_shift = []\n",
    "\n",
    "for i, uid in enumerate(idd):\n",
    "    # load data\n",
    "    cond = \"dd\"\n",
    "    #load the appropriate file\n",
    "    mat = scipy.io.loadmat(f\"{PATH_EEG}/correlation_shift_ERSP_{cond}_{subj_to_inlcude[i]}.mat\")\n",
    "\n",
    "    # get the data out if the mat file\n",
    "    mat = mat[\"corr_coef\"]\n",
    "    mat = pd.DataFrame(mat).transpose()\n",
    "    # save the median correlation for each shift condition\n",
    "    no_shift = no_shift + [np.median(mat[mat[0] != 0][0].tolist())]\n",
    "    pos_shift = pos_shift + [np.median(mat[mat[1] != 0][1].tolist())]\n",
    "    neg_shift = neg_shift + [np.median(mat[mat[2] != 0][2].tolist())]\n",
    "\n",
    "\n",
    "# create df\n",
    "corr_long = {}\n",
    "corr_long['subject'] = [int(li) for li in np.linspace(0,18,19)] * 3 # subject nr\n",
    "corr_long['shift'] = ['no_shift'] * len(no_shift) + ['pos_shift'] * len(pos_shift) + ['neg_shift'] * len(neg_shift)\n",
    "corr_long['corr_coef'] = no_shift + pos_shift + neg_shift\n",
    "corr_long = pd.DataFrame(corr_long)\n",
    "\n",
    "### Repeated measure ANOVA\n",
    "print(\"Repeated measure ANOVA\")\n",
    "print(AnovaRM(data=corr_long, depvar='corr_coef',\n",
    "              subject='subject', within=['shift']).fit())\n",
    "\n",
    "print()\n",
    "### Check Assumtions:\n",
    "# 1. Sphericity using the Mauchly test\n",
    "mauchly_result = pg.sphericity(corr_long, dv='corr_coef', subject='subject', \n",
    "                               within='shift')\n",
    "print(mauchly_result)\n",
    "print()\n",
    "\n",
    "### Compute pairwise comparisons with Fisher's LSD test\n",
    "stat,p1 = scipy.stats.ttest_rel(no_shift, pos_shift)\n",
    "stat,p2 = scipy.stats.ttest_rel(no_shift, neg_shift)\n",
    "stat,p3 = scipy.stats.ttest_rel(pos_shift, neg_shift)\n",
    "p_values = [p1,p2,p3]\n",
    "\n",
    "print([round(pv,3) for pv in p_values])\n",
    "print()\n",
    "print('corrected p-values')\n",
    "corrected_p_values = multipletests(p_values, alpha=0.05, method='bonferroni')[1]\n",
    "print(corrected_p_values)\n",
    "corrected_p_values = [round(pv, 3) for pv in corrected_p_values]\n",
    "# Print the corrected p-value4\n",
    "print(corrected_p_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf31b183-0152-4519-9fa4-b4bcf931da11",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Plot for both correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2714c78e-e9ec-4c0c-96d3-ca1dc96c88b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the correlations of ERPs and ERSPs\n",
    "\n",
    "# define\n",
    "labelsize = 40 #text\n",
    "legendsize = 40 #ledgend\n",
    "ticksize = 30 #ticks\n",
    "numbersize = 60 #A, B etc.\n",
    "fname = \"Arial\" # font name\n",
    "pallet = [gaze_color_1,sacc_color_1,vel_eye_color]\n",
    "\n",
    "# set up figure\n",
    "plt.figure(figsize=(30, 20), constrained_layout=True)\n",
    "sns.set_style(\"white\") \n",
    "ax1 = plt.subplot2grid(shape=(2, 3), loc=(0, 0), rowspan=2, colspan=1)\n",
    "ax2 = plt.subplot2grid(shape=(2, 3), loc=(0, 1), rowspan=1, colspan=2)\n",
    "ax3 = plt.subplot2grid(shape=(2, 3), loc=(1, 1), rowspan=1, colspan=2)\n",
    "\n",
    "# lists to save the individual subject medians\n",
    "no_shift = []\n",
    "pos_shift = []\n",
    "neg_shift = []\n",
    "\n",
    "# plot ERPs and ERSPs\n",
    "for i in range(2):\n",
    "    if i == 0:\n",
    "        mat = scipy.io.loadmat(f\"{PATH_EEG}/correlation_shift_dd_{subj_to_inlcude[i]}.mat\")\n",
    "    else:\n",
    "        mat = scipy.io.loadmat(f\"{PATH_EEG}/correlation_shift_ERSP_dd_{subj_to_inlcude[i]}.mat\")\n",
    "\n",
    "    # get the data out if the mat file\n",
    "    mat = mat[\"corr_coef\"]\n",
    "    mat = pd.DataFrame(mat).transpose()\n",
    "    # plot the bars for no-shift and the two shift conditions for the first subject\n",
    "    ax1.bar(i,mat[mat[0] != 0][0].median(),width = 0.2, color = pallet[0], alpha=0.7, label='No Shift')\n",
    "    ax1.bar(i+0.2,mat[mat[1] != 0][1].median(),width = 0.2, color = pallet[1], alpha=0.7, label='Positive Shift')\n",
    "    ax1.bar(i+0.4,mat[mat[2] != 0][2].median(),width = 0.2, color = pallet[2], alpha=0.7, label='Negative Shift')\n",
    "    # set labels\n",
    "    ax1.set_ylabel(\"Correlation of Trials and Avg. ERP/ERSP\", fontsize=labelsize, fontname=fname)\n",
    "    # set ticks\n",
    "    for label in ax1.get_xticklabels(): # change tick font\n",
    "        label.set_fontproperties(fname)\n",
    "    for label in ax1.get_yticklabels():\n",
    "        label.set_fontproperties(fname)\n",
    "    ax1.set_xticks(np.linspace(0.2, 1.2, num=2),['ERP','ERSP'],fontsize=labelsize)\n",
    "    ax1.set_yticks(np.linspace(0, 0.6, num=7))\n",
    "    ax1.yaxis.set_tick_params(labelsize=ticksize)  # change tick size\n",
    "    \n",
    "    #display(mat[mat[0] != 0][0].median())\n",
    "    \n",
    "    mat = mat.rename(columns={0: \"no_shift\", 1: \"pos_shift\", 2: \"neg_shift\"})\n",
    "    # for easier code, set the axis\n",
    "    if i == 0: \n",
    "        axis = ax2\n",
    "    else:\n",
    "        axis = ax3\n",
    "    # plot the across subject data  \n",
    "    ax = sns.kdeplot(mat[\"no_shift\"], color=pallet[0], ax = axis, lw=4, fill=True, alpha = 0.2, label=\"No Shift\")\n",
    "    ax = sns.kdeplot(mat[\"pos_shift\"], color=pallet[1], ax = axis, lw=4, fill=True, alpha = 0.2, label=\"Positive Shift\")\n",
    "    ax = sns.kdeplot(mat[\"neg_shift\"], color=pallet[2], ax = axis, lw=4, fill=True, alpha = 0.2, label=\"Negative Shift\")\n",
    "    # set the axis labels and ticks\n",
    "    for label in axis.get_xticklabels(): # change tick font\n",
    "        label.set_fontproperties(fname)\n",
    "    for label in axis.get_yticklabels():\n",
    "        label.set_fontproperties(fname)\n",
    "    ax.set_xlim(-1, 1)\n",
    "    ax.set_ylim(0, 3.1)\n",
    "    ax.set_xlabel(\"Correlation\", fontsize=labelsize, fontname=fname)\n",
    "    ax.set_ylabel(\"Density\", fontsize=labelsize, fontname=fname)\n",
    "    ax.set_xticks(np.linspace(-1, 1, num=5))\n",
    "    ax.set_yticks(np.linspace(0.0, 3, num=4))\n",
    "    ax.xaxis.set_tick_params(labelsize=ticksize)  # change tick size\n",
    "    ax.yaxis.set_tick_params(labelsize=ticksize)  # change tick size\n",
    "\n",
    "    # for one plot, display the ledgend\n",
    "    ax2.legend(loc=\"upper right\", fontsize=legendsize)\n",
    "\n",
    "    ax1.set_title(\"A\", fontsize=numbersize, fontweight=\"bold\",loc=\"left\", x=-0.09, y=1.02199, pad=-30, fontname=fname) \n",
    "    ax2.set_title(\"B\", fontsize=numbersize, fontweight=\"bold\",loc=\"left\", x=-0.055, y=1.05, pad=-30, fontname=fname) \n",
    "    ax3.set_title(\"C\", fontsize=numbersize, fontweight=\"bold\",loc=\"left\", x=-0.055, y=1.05, pad=-30, fontname=fname) \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (wd_village)",
   "language": "python",
   "name": "wd_village"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
